\documentclass[]{article}

\usepackage{anysize}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{enumerate}
\usepackage{cancel}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{color}

%%% for citations. See Lucy's tutorial: https://github.com/LucyMcGowan/Tutorials/blob/master/BiblatexTutorial.md
\usepackage[backend=biber,maxnames=10,citestyle=science]{biblatex}
\addbibresource{summaryOfRef.bib}

%%% when using biber as a "backend" compile like this:
% pdflatex myFile
% biber myFile
% pdflatex myFile


\let\epsilon\varepsilon
\newcommand\SLASH{\char`\\}
\newcommand{\csch}{\text{csch}}
\marginsize{0.5in}{1in}{0.5in}{1in}
\setlength\parindent{0pt}

% Title Page: Modify as needed
\title{Summary for Bryan's research}
\author{Summarized by Svetlana Eden}
\date{Month Day, 2015}

\hypersetup{hidelinks}

% \usepackage[pdftex,bookmarks,pagebackref,pdfpagemode=UseOutlines,
%      colorlinks,linkcolor=\linkcol,
%      pdfauthor={Svetlana K Eden},
%      pdftitle={\titl}]{hyperref}


\begin{document}
\maketitle
\tableofcontents
\listoffigures
\listoftables
\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Matrix algebra
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Matrix algebra
\section{Oral Exam Stuff}
Survival analysis is a well researched topic: time to event, time to event with censoring, multiple events, competing risk events, current status analysis. We are interested in association of two survival events. For example, we could be interested in time to breast cancer diagnosis in mothers and their daughters. It could also be a time to an onset of an opportunistic infection and time to viral failure in HIV infected patients. These motivating examples include paired survival, but in general, survival data doesn't have to be paired. The interest to bivariate survival to the best of our knowledge goes back to Clayton (1978)[??? check this]. Since then different methods were employed to address this question.\\
~\\
\begin{itemize}
	\item Evaluation of the bivariate survival function with two marginals and a correlation component:
	Dabrowska, Pruitt, Prentice, Van Der Laan.
	\item Martingale residuals (Sih\&Louice, [??? look for more papers on martingale residuals])
	\item sort of hazard ratio for bivariate surviaval (Clayton, Fan, Oakes, Sankaran et al)
	\item copulas (zhang2008, [??? provide more references on copulas])
	\item other regression residuals (Cuzick1982, Prentice)
	\item Kendall's tau: weighted, global, local. 
	\item distance measure [??? not sure if I want to address this]
	\item Spearman correlation (Dabrowska1986, Ding2012, Cuzick1982)
	\item Probability scale residuals, PSR (Li\&Shepard)
	\item Challanges and limitations (discrete data covariates)
	\item Qi - covariates (look at prentice and Cuzick)
	\item show that this is Spearman
	\item apply to dataset
	\item simmulations
	\item explore performance of partial and conditional Spearman.
\end{itemize}

Correlation of PSR is in fact a Spearman correlation generalized to the case with sensoring. Although, this kind of association was covered by (Cuzick1982, Dabrowska1986, Ding2012), they mentioned only a continuous case. PSR of (Li\&Shepard) are generalized to discrete case for the case of independent censoring and for the case of currents status data.\\
~\\
Future direction. We want to compare the performance of PSR to the performance of martingale residuals for the discrete case.

\section*{Introduction}
The interest in survival outcome can be traced back to year 1846, when a Hungarian doctor of the Vienna General Hospital maternity clinic, Ignaz Semmelweis, collected data on the rate of death from childbed fever. He hypothesized that a child birth is helped by a doctor or a medical student, the women's rate of death from childbed fever is higher because of a disease that is caused by cadaverous particles that medical students and doctors have on on their hands after disecting cadavras. Jumping forward about 100 years, survival data was routinely collected and used by hospital, agencies, and governments [READ YOUR epidemiology book]. The recorded data were used to estimate rates of death and other events.

\subsection{1949-1970}
Hald in 1949 ["Maximum Likelihood estimation of th eparameters of a normal distribution which is trancated at a known point", \emph{Skandinavisk Aktuarielidskrift, 32 (1949)}, 119-134], suggested a more complex view of survival data and introduced a concept of sensoring. This concept elegantly taken into accout by one of the most famous work on survival, Kaplan and Meier [1958, p.459]. Cox (1972) extended Kaplan\&Meier results even further and introduced a regression model for censored suvival data. His model utilized a concept of a \emph{hazard rate}:
$$
\begin{aligned}
	\lambda(s|y) &= \frac{\partial}{\partial s}\left\{  -log \mathcal{S}(s|y)  \right\} =
	             \frac{f(s|y)}{\mathcal{S}(s|y)}
\end{aligned}
$$
Where $\mathcal{S}(s|y) = 1-F(s|y)$, and $F(s|y)$ and $f(s|y)$ are cumulative distribution function and density function respectively. In the same paper (p.195) he also generalized his model for a case when one subject can have two events.\\
Unlike Cox, Basu (1971) [get this paper from the library ??? this does not add up because Cox wrote his paper later] considered a \emph{paired} bivariate survival with the hazard rate defined as:
$$
\begin{aligned}
	\lambda(s,t) &= \frac{f(s,t)}{\mathcal{S}(s,t)} = \frac{\partial}{\partial s}\left\{  -log \mathcal{S}(s,t)  \right\}\frac{\partial}{\partial t}\left\{  -log \mathcal{S}(s,t)  \right\} - \frac{\partial^2}{\partial s\partial t}\left\{  -log \mathcal{S}(s,t)  \right\}
\end{aligned}
$$

\subsection{1978}

\subsubsection{Clayton, 1978}
Later in 1978, Clayton [???] addressed a question of association between paired survival times of fathers and sons and defined a measure similar to harzard ratio. He wanted this measure to be
\begin{enumerate}
	\item  easy to compute
	\item expressible as a constant ratio of age-specific rates
  \item symmetrical in two variables
\end{enumerate}
If we denote time to event for fathers to be $s$ and time to event for sons to be $t$, this measure can be written in the following way:
$$
\begin{aligned}
	\theta = \frac{\lambda_s(s_0|t=t_0)}{\lambda_s(s_0|t>t_0)} = \frac{\lambda_t(t_0|s=s_0)}{\lambda_t(t_0|s>s_0)}
\end{aligned}
$$
The requirement of symmetry is motivated by the fact than neither son nor father are causes of event, rather, there is an unobservable variable that is associated with the event for both of them.

This measure can be interpreted for sons (as much as for fathers) in the following way: how much more likely for a son to have an event at time $s_0$ given that his father had an event at time $t_0$ compared to a son whose father survived until time $t_0$ without the event.

Independence between fathers and sons would mean $\theta = 1$, positive association $\theta > 1$ and negative association $\theta < 1$. Clayton also explained how his model could be generalized to include covariates, and in estimating the model he adopts an approach similar to Cox's. He also derived likelihood for estimating $\theta$ when two marginal distributions are completely unknown.\\

Note that although Clayton developed $\theta$ in the context of a model, the model was not necessacery to check independence. Independence could be checked by evaluating $\theta$.\\

\subsubsection{Prentice, 1978}
Prentice cosidered a linear regression with censored outcome.
	$$
	\begin{aligned}
		y = \alpha + \beta z + \sigma e
	\end{aligned}
	$$
Although this formulation sets up a context for univariate survival, we are interested in this paper for several reasons. The author's goal was to develop a \emph{liear rank statistic} in order to check the hypothesis of $\beta = 0$. In order to do this he had to find an approach to rank survival outcome in the presence of censored data. He chose a simplified approach to the ranking of censored values [Kalbfleisch \& Prentice, 1973]. According to this approach, uncensored observations are ranked between themselves. Censored observations that are located between two adjacent uncencored observations are arbitrarily ranked. This approach allowed to develop linear rank statistic and its approximation that assigned the same score to all censored residuals between adjacent uncensored values.

Even after using ranks and approximations, Prentice's approach required assuming $F_i$ - distribution of residuals (check this please).

\subsection{1982}

\subsubsection{Oakes, 1982}
Oakes (1982 ??? reference [YOU DIDN'T COVER THIS BEFORE]) criticised Clayton's likelihood approach to estimating $\theta$ [make sure that you know speficic critisizm points] and introduced an alternative method based on \emph{Kendall}'s $\tau$, coefficient of concordance. In 1989 he also introduced a bivariate survival model based on \emph{frailties}: an unobserved variable that induces dependence between two survival times that both depend on this variable. In the context of this model, he further utilized coefficient $\theta$ introduced by Clayton. He also noted that bivariate distributions introduced by frailty models are part of a larger class of archimedian distributions studied by Genest and MacKay (1986a,b [I did not read their papers and not sure if I should]):
$$
\begin{aligned}
	S(t) = p\left[ q\left\{ S_1(t_1) \right\}  + q\left\{ S_2(t_2) \right\}  \right]
\end{aligned}
$$
Where $p(u)$ is an inverse function of $q(v)$. He shows how to estimate his model in the presence of censoring in either one or both components. He showed that in the context of his model, $\theta$ and \emph{Kendall}'s $\tau$ were related through the following equality: $\tau(v) = \frac{\theta(v)-1}{\theta(v)+1}$, where $v=S(t_1, t_2)$ [I am not sure if all this is necessary].

\subsubsection{Cuzick, 1982, Have not started yet.}
Considers a general model of association:
	$$
	\begin{aligned}
		Y_1 = aZ + e_1 ~~~~~~~~ Y_2 = bZ + e_2
	\end{aligned}
	$$

Where $Z$, $e_1$, and $e_2$ are independent. He considers two cases, and only the second case is relevant for us, when $b=a\lambda,~~0<|\lambda|<\infty$. In this case two variables $(Y_1, Y_2)$ are thought to be related to a third unobserved covariate.\\
He assumed the same generalized ranking of censored data as Prentice (1978). Also, similar to Prentice (1978), Cuzick's approach required knowing $f_i(x)$ the density of $Y_i$ (or of $e_i$?). He illustrated his approach by showing that when this density is logistic, $f(x) = 2\pi_{-1} e^{-x}/(1+e^{-x})^2$, then the rank of each observation is $F(x)$ with no censoring, and $\frac{1+F(x)}{2}$, when censoring is present - \textbf{PSR}

\subsection{Dabrowska, 1986 \cite{dabrowska1986rank}}
Has developed further the approach of [Prentice, 1978], [Kalbfleisch \& Prentice, 1980], and [Cuzick, 1982], in order to check a null hypothesis of independence $H_0:~F=F_1 F_2$. The author suggested that  the following \emph{linear rank} statistic can be used
	$$
	\begin{aligned}
		 &\sum_{n=1}^N a_1(R_{1n}, \delta_{1n})\cdot a_2(R_{2n}, \delta_{2n}), ~i=1,2\\
		 &~~~~~ a_i(j,d) = E\mathcal{J}(U_{(j)}, d)\prod_{k=1}^{N_i} m_{ik}(1-U_{(k)}^{a_{ik}}
	\end{aligned}
	$$
Where: 
	$$
	\begin{aligned}
		 R_in &= \#\{m:~Y_{im} \leq Y_{in}, \delta_{im}=1   \}\\
		 a_{ik} &= \# \{n: ~R_{in}=k,~\delta_{in}=0\}\\
		 m_{ik} &= \# \{n: ~R_{in}\geq k\}\\
		 \delta_{im}&=1,~if~subject ~m~from~group~i~has~an~event\\
		 U_{(k)}~&independent ~ordered~sample~from~Uniform~distribution\\
		 \mathcal{J}(u,d) ~&is~such~that:~~\int_0^u \mathcal{J}_i(v,1)dv = -(1-u)\mathcal{J}_i(u,0)
	\end{aligned}
	$$
The author showed that the choice of $\mathcal{J}_i(u,d) =d-(1+d)u$ corresponds to the cencored-data version of the Spearman test. She also notes that the exact scores are hard to compute, so an approximate test statistics  can be used:
	$$
	\begin{aligned}
		 S_n = \sum_{n=1}^N \mathcal{J}_1( \hat{F}_1, \delta_{1n}) \cdot \mathcal{J}_2( \hat{F}_2, \delta_{2n})
	\end{aligned}
	$$
Substituting $\mathcal{J}_i(u,d) =d-(1+d)u$ into the above expression, we get:
	$$
	\begin{aligned}
		 S_n &= \sum_{n=1}^N (\hat{F}_1 - \delta_{1n}(1-\hat{F}_1))\cdot (\hat{F}_2 - \delta_{2n}(1-\hat{F}_2))\\
	\end{aligned}
	$$
Where $\hat{F}_i$ are estimators close to the usual \emph{Kaplan-Meier} estimators of the marginal \emph{CDF}'s. If we look at the above expression closely: it reminds us of $E[PSR_1 \cdot PSR_2]$, where $PSR(x, \delta) = F(x)-\delta(1-F(x))$ is a probability scale residual, \textbf{PSR}, for \emph{continuous case}.


\textbf{Show the resemblence with archemedian copulas}

\textbf{READ: Hanley, J. A., and Parnes, M. N. (1983), "Nonparametric Estimation of a Multivariate Distribution in the Presence of Censoring," Biometrics, 39, 129-139.}




\section{PSR (probability scale residuals) for censored data}
% Terms for residuals:
% \begin{itemize}
% 	\item \textbf{OMER}-observed minus expected residuals: $E(y-Y^*) = y - \hat{y}$
% 	\item \textbf{PSR}-probability scale residuals: $E{sign(y,Y^*)} = pr(Y^* < y) - pr(Y^* > y)$
% \end{itemize}
PSR are defined as $r(t,F^*) = E\{sign(y,Y^*)\} = pr(Y^* < y) - pr(Y^* > y) = F^*(t-) - (1-F^*(y)) = F^*(t-) - 1 + F^*(t)$.\\
Since we do not always observe $t$, the PSR must be defined in terms of $y$ (time to event or censoring) and $\delta$ (if the event happened or not). \\
\\
\textbf{By definition}, $r(y,F^*, \delta) = r(t,F^*|\Delta=\delta)$.\\
If $\delta = 1$, then $t=y$ and $r(y,F^*, \delta=1) = F^*(y-) - 1 + F^*(y)$. \\
If $\delta = 0$, then $t$ is unknown, except that it occurs some time after the censoring time $y$, so $r(t,F^*, \delta=0) = E\{r(t,F^*)|T^*>y\}$. Let's find it:
	$$
	\begin{aligned}
		E\{r(t,F^*)|T^*>y\} &= \frac{\int_{t>y}r(t,F^*)dF^*(t)}{1-F^*(t)}= \frac{\int_{t>y}(F^*(t-) - 1 + F^*(t))dF^*(t)}{1-F^*(y)}= \frac{\int_{t>y}F^*(t-)dF^*(t) - \int_{t>y}(1 - F^*(t))dF^*(t)}{1-F^*(y)}=\\
		&= \frac{\int_{t>y}\int_{s<t}dF^*(s)dF^*(t) - \int_{t>y}\int_{s>t}dF^*(s)dF^*(t)}{1-F^*(y)}= \frac{\int_{t>y}\int_{s<t}dF^*(s)dF^*(t) - \int\int_{y<t<s}dF^*(s)dF^*(t)}{1-F^*(y)}=\\
		&= \frac{\left[\int\int_{s<y<t}dF^*(s)dF^*(t) + \int\int_{y<s<t}dF^*(s)dF^*(t)\right] - \int\int_{y<t<s}dF^*(s)dF^*(t)}{1-F^*(y)}\\
	\end{aligned}
	$$
Because $t$ and $s$ are symmetric, $\int\int_{y<s<t}dF^*(s)dF^*(t) = \int\int_{y<t<s}dF^*(s)dF^*(t)$, so we have:
	$$
	\begin{aligned}
		E\{r(t,F^*)|T^*>y\} &= \frac{\left[\int\int_{s<y<t}dF^*(s)dF^*(t) + \cancel{\int\int_{y<s<t}dF^*(s)dF^*(t)}\right] - \cancel{\int\int_{y<t<s}dF^*(s)dF^*(t)}}{1-F^*(y)}\\
		&= \frac{\int\int_{s<y<t}dF^*(s)dF^*(t)}{1-F^*(y)} = \frac{(1-F^*(y))\int_{s<y}dF^*(s)}{1-F^*(t)} = \frac{\cancel{(1-F^*(y))}F^*(y)}{\cancel{1-F^*(y)}} =\\
		&=F^*(y)
	\end{aligned}
	$$
	
Therefore for sensored data:
	$$
	\begin{aligned}
		r(y, F^*) &= F^*(y) + F^*(y-) - 1,~~~&\delta = 1 \\
		r(y, F^*) &= F^*(y) ,~~~&\delta = 0 \\
	\end{aligned}
	$$
or $r(y, F^*) = F^*(y) + \delta((F^*(y-) - 1)$.

\subsection{Spearman correlation and PSR correlation for continuous censored outcome}
Here we show that if we define Spearman correlation for continuous and censored outcomes a certain way, we then Spearman correlation and PSR correlation for ontinuous censored outcome are equivalent.\\
~\\
Spearman correlation for continuous outcome can be defined as $cor(F_S(s), F_T(t))$ (reference ???). In case of censored outcomes however, we don't always know $s$ and $t$. This means that we have to redefine Spearman correlation in a different way. In the following section we use $S$, $C$, $\delta=I(S\leq C)$, $X = min(S, C)$ for the first outcome and $T$, $D$, $\epsilon=I(T\leq D)$, $Y = min(T, D)$ for the second.\\
Let's modify the definition of the Spearman correlation in the following way. When $\delta = 1$ or $S\leq C$, we have that $X = min(S, C)=S$ and instead of $F_S(s)$ we can take $F_S(x)$. When $\delta = 0$ or $S > C$, we have that $X = min(S, C)=C$ and instead of $F_S(s)$ we can take $E_S[F_S(s)|S>x]$. Let's compute $E_S[F_S(s)|S>x]$:
	$$
	\begin{aligned}
		E_S[F_S(x)|S>x] &= \frac{1}{1-F_S(x)}\int_{(x, \infty)} F_S(s)dF_S(s) = \frac{1}{1-F_S(x)} \left.\frac{ [F_S(s)]^2}{2}\right|_{(x, \infty)} = \frac{1-[F_S(x-)]^2}{2(1-F_S(x))} \\
	\end{aligned}
	$$
Since we are focusing now on the continuous case, we can assume that $F_S(x)=F_S(x-)$ therefore we have
	$$
	\begin{aligned}
		E_S[F_S(x)|S>X] &=\frac{1-[F_S(x)]^2}{2(1-F_S(x))}=\frac{\cancel{(1-F_S(x))}(1+F_S(x))}{2\cancel{(1-F_S(x))}}  = \frac{1+F_S(x)}{2} \\
	\end{aligned}
	$$
So, instead of looking at the Spearman correlation as correlation of $F_S(s)$ and $F_T(t)$, we redefine correlation as:
	$$
	\begin{aligned}
		Spearman~correlation~&=~ cor\left(  \delta F_S(x) + (1-\delta) \frac{1+F_S(x)}{2},~\epsilon F_T(y) + (1-\epsilon) \frac{1+F_T(y)}{2}  \right)\\
		&=~ cor\left(  \frac{1+\delta}{2}F_S(x) +  \frac{1-\delta}{2},~\frac{1+\epsilon}{2}F_T(y) +  \frac{1-\epsilon}{2}  \right)\\
		&=~ cor\left(  (1+\delta)F_S(x) +  1-\delta,~(1+\epsilon)F_T(y) +  1-\epsilon  \right)\\
	\end{aligned}
	$$
It is easy to check that in the continous case, the above expression is the same as: 
	$$
	\begin{aligned}
		PSR~correlation~&=~ cor\left(  (1+\delta)F_S(x) -\delta,~(1+\epsilon)F_T(y) -\epsilon  \right)\\
	\end{aligned}
	$$

\subsection{Spearman correlation and PSR correlation for discrete censored outcome}
For discrete case, Spearman correlation can be defined as (???):
	$$
	\begin{aligned}
		cor\left( \frac{F_S(s) + F_S(s-)}{2},~\frac{F_T(t) + F_T(t-)}{2} \right)\\
	\end{aligned}
	$$
So let's find $E_S[F_S(x)|S>x]$ for the discrete case. First (just to get started) let's derive $E_S[F_S(x)]$. We denote $Pr\left\{S=s\right\}$ as $P_s$:
	$$
	\begin{aligned}
		E_S[F_S(x)] &= \sum_{i=0}^{\infty}F_S(i)P_i = \sum_{i=0}^{\infty}\left( \sum_{k=0}^{i}P_k \right)P_i =\\
		&= (P_0 P_0) + (P_0 P_1 + P_1 P_1) + (P_0 P_2 + P_1 P_2 + P_2 P_2) + ...= \\
		&= P_0^2 + P_1^2 + P_2^2 + ... + P_0 P_1 + P_0 P_2 + P_2 P_1 + ... =\frac{1}{2}(P_0 + P_1 + P_2 + ...)^2 + \frac{1}{2}(P_0^2 + P_1^2 + P_2^2 + ...) =\\
		&= \frac{1}{2} + \frac{1}{2}\sum_{i=0}^{\infty}P_i^2
	\end{aligned}
	$$
Now we are equiped to compute $E_S[F_S(x)|S>x]$:
	$$
	\begin{aligned}
		E_S[F_S(x)|S>x] &= \frac{1}{1-F_S(x)} \sum_{i=x+1}^{\infty}F_S(i)P_i = \frac{1}{1-F_S(x)}\sum_{i=x+1}^{\infty}\left( \sum_{k=0}^{i}P_k \right)P_i =\\
		 &= \frac{1}{1-F_S(x)}\left[ \sum_{i=0}^{\infty}\left( \sum_{k=0}^{i}P_k \right)P_i - \sum_{i=0}^{x}\left( \sum_{k=0}^{i}P_k \right)P_i   \right] = \\
		 &= \frac{1}{1-F_S(x)}\left[ \frac{1}{2} + \frac{1}{2}\sum_{i=0}^{\infty}P_i^2 -  \frac{1}{2} \left\{ \left(\sum_{i=0}^{x}P_i\right)^2 + \sum_{i=0}^{x}P_i^2  \right\}    \right] = \\
		 &= \frac{ 1 - F_S^2(x) + \sum_{i=x+1}^{\infty}P_i^2 }{2(1-F_S(x))}\\
	\end{aligned}
	$$

Our next challenge is to compute $E_S[F_S(x-)|S>x]$. We assume that $F_S(0-)=0$:
	$$
	\begin{aligned}
		E_S[F_S(x-)|S>x] &= \frac{1}{1-F_S(x)} \sum_{i=x+1}^{\infty}F_S(i-1)P_i = \frac{1}{1-F_S(x)}\sum_{i=x+1}^{\infty}\left( \sum_{k=0}^{i-1}P_k \right)P_i =\\
		 &= \frac{1}{1-F_S(x)}\left[ \sum_{i=0}^{\infty}\left( \sum_{k=0}^{i-1}P_k \right)P_i - \sum_{i=0}^{x}\left( \sum_{k=0}^{i-1}P_k \right)P_i   \right] = \\
		 &= \frac{1}{1-F_S(x)}\left[ \frac{1}{2} - \frac{1}{2}\sum_{i=0}^{\infty}P_i^2 -  \frac{1}{2} \left\{ \left(\sum_{i=0}^{x}P_i\right)^2 - \sum_{i=0}^{x}P_i^2  \right\}    \right] = \\
		 &= \frac{ 1 - F_S^2(x) - \sum_{i=x+1}^{\infty}P_i^2 }{2(1-F_S(x))}\\
	\end{aligned}
	$$
Now, let's recall that in the discrete case each Spearman correlation component is $\frac{F_S(s) + F_S(s-)}{2}$, so let's compute it for the case when $\delta=0$:
	$$
	\begin{aligned}
	  \frac{E_S[F_S(x)|S>x] + E_S[F_S(x-)|S>x]}{2} &= \frac{1}{2}\left[\frac{ 1 - F_S^2(x) + \sum_{i=x+1}^{\infty}P_i^2 }{2(1-F_S(x))}   +   \frac{ 1 - F_S^2(x) - \sum_{i=x+1}^{\infty}P_i^2 }{2(1-F_S(x))}\right]=\\
		&= \frac{1 - F_S^2(x)}{2(1-F_S(x))}= \frac{1 + F_S(x)}{2}\\
	\end{aligned}
	$$
As a result, we have:
	$$
	\begin{aligned}
		Spearman~correlation~&=~ cor\left(  \delta\frac{F_S(x) + F_S(x-)}{2} + (1-\delta) \frac{1 + F_S(x)}{2}, ~\epsilon\frac{F_T(y) + F_T(y-)}{2} + (1-\epsilon) \frac{1 + F_T(y)}{2} \right)=\\
		&=~ cor\left(  \delta( F_S(x) + F_S(x-)) + (1-\delta) (1 + F_S(x)), ~\epsilon (F_T(y) + F_T(y-)) + (1-\epsilon) (1 + F_T(y)) \right)=\\
		&=~ cor\left( \cancel{\delta F_S(x)} + \delta F_S(x-) +  1 + F_S(x) -\delta - \cancel{\delta F_S(x)}, ~\cancel{\epsilon F_T(y)} + \epsilon F_T(y-) + 1 + F_T(y)-\epsilon -\cancel{\epsilon F_T(y)}   \right)=\\
		&=~ cor\left( F_S(x) + \delta F_S(x-) +  1 -\delta , ~ F_T(y) + \epsilon F_T(y-) + 1 -\epsilon   \right)\\
	\end{aligned}
	$$
It can be easily shown that the above expression is the same as correlation of \emph{PSR}:
	$$
	\begin{aligned}
		PSR~correlation~&=~ cor\left(  F_S(x) + \delta F_S(x-) -\delta,~F_T(y) + \epsilon F_T(y-) -\epsilon  \right)\\
	\end{aligned}
	$$

\subsection{Spearman correlation and PSR based on a different definition.}
Up to now, in order to prove the equivalence of \emph{Spearman} corrlation and the correltation of the PSR we have been using the following defition of \emph{Spearman} correlation: $corr(F_S(s), F_T(t))$. In this section, we show that if we start with the original definition, $E(sign(S_1-S_0)sign(T_2-T_0))$, we will get the same result. Let's see why. Keeping in mind that $S_1 \perp T_2$ we can write:
	$$
	\begin{aligned}
		E(sign(S_1-S_0)sign(T_2-T_0)) &= E_{(S,T)}\left\{ E[sign(S_1-S_0)sign(T_2-T_0) |(S_1,T_2)] \right\} = \\
		  &= E_{(S,T)}\left\{ E[sign(S_1-S_0) |S_1]  E[sign(T_2-T_0) |T_2] \right\} = \\
		  &= E_{(S,T)}\left\{ [ P(S_0 < S_1|S_1) - P(S_0 > S_1|S_1) ] \cdot  [P(T_0 < T_2|T_2) - P(T_0 > T_2|T_2)] \right\}
	\end{aligned}
	$$
 Now, let's look at the expression $P(S_0 < S_1|S_1) - P(S_0 > S_1|S_1)$. We already know that in case of no censoring, $P(S_0 < S_1|S_1) - P(S_0 > S_1|S_1) = PSR(S_1)$. When censoring takes place, we don't observe $S_1$, but we still obsere $x_1$, so similarly to the previous section, instead of $P(S_0 < S_1|S_1) - P(S_0 > S_1|S_1)$ we can take:
	$$
	\begin{aligned}
		 E_{S_0>x_1}[P(S_0 < x_1)|S_0>x_1] - E_{S_0>x_1}[P(S_0 > x_1)|S_0>x_1]&= 0 - \frac{1}{1-F_S(S>x_1)}\int_{(x_1, \infty)} F_S(s)dF_S(s)
	\end{aligned}
	$$
We have already proved in the previous sections, that taking a correlation of the product of the right hand side expressions above results in Spearman correlation (the minus signs cancel out).

\subsection{Rank tests for independence for bivariate censored data (Dabrowska) \cite{dabrowska1986rank}}
For null hypothesis $H_0:~F=F_1 F_2$, the following \emph{linear rank} statistic can be used
	$$
	\begin{aligned}
		 &\sum_{n=1}^N a_1(R_{1n}, \delta_{1n})\cdot a_2(R_{2n}, \delta_{2n}), ~i=1,2\\
		 &~~~~~ a_i(j,d) = E\mathcal{J}(U_{(j)}, d)\prod_{k=1}^{N_i} m_{ik}(1-U_{(k)}^{a_{ik}}
	\end{aligned}
	$$
Where: 
	$$
	\begin{aligned}
		 R_in &= \#\{m:~Y_{im} \leq Y_{in}, \delta_{im}=1   \}\\
		 a_{ik} &= \# \{n: ~R_{in}=k,~\delta_{in}=0\}\\
		 m_{ik} &= \# \{n: ~R_{in}\geq k\}\\
		 \delta_{im}&=1,~if~subject ~m~from~group~i~has~an~event\\
		 U_{(k)}~&independent ~ordered~sample~from~Uniform~distribution\\
		 \mathcal{J}(u,d) ~&is~such~that:~~\int_0^u \mathcal{J}_i(v,1)dv = -(1-u)\mathcal{J}_i(u,0)
	\end{aligned}
	$$
The author then says that the choice of $\mathcal{J}_i(u,d) =d-(1+d)u$ corresponds to the cencored-data version of the Spearman test. She also notes that the exact scores are hard to compute, so an approximate test statistics  can be used:
	$$
	\begin{aligned}
		 S_n = \sum_{n=1}^N \mathcal{J}_1( \hat{F}_1, \delta_{1n}) \cdot \mathcal{J}_2( \hat{F}_2, \delta_{2n})
	\end{aligned}
	$$
Substituting $\mathcal{J}_i(u,d) =d-(1+d)u$ into the above expression, we get:
	$$
	\begin{aligned}
		 S_n &= \sum_{n=1}^N (\delta_{1n} - (1+\delta_{1n})\hat{F}_1(Y_{1n}))\cdot (\delta_{2n} - (1+\delta_{2n})\hat{F}_1(Y_{2n})) =\\
		 &= \sum_{n=1}^N (-\hat{F}_1(Y_{1n}) + \delta_{1n}(1-\hat{F}_1(Y_{1n})))\cdot (-\hat{F}_2(Y_{2n}) + \delta_{2n}(1-\hat{F}_2(Y_{2n})))\\
	\end{aligned}
	$$
Where $\hat{F}_i$ are estimators close to the usual \emph{Kaplan-Meier} estimators of the marginal \emph{CDF}'s. If we look at the above expression closely:
	$$
	\begin{aligned}
		 S_n &= \sum_{n=1}^N (\hat{F}_1 - \delta_{1n}(1-\hat{F}_1))\cdot (\hat{F}_2 - \delta_{2n}(1-\hat{F}_2))\\
	\end{aligned}
	$$
it reminds us of $E[PSR_1 \cdot PSR_2]$, where $PSR(x, \delta) = F(x)-\delta(1-F(x))$ is a probability scale residual for \emph{continuous case}.

\subsection{Ding, Wang, 2012: Testing Independence for Bivariate Current Status Data, ref???}
Suggested two statistics for testing independence for bivariate \emph{current status data}. One is based on counts (how many events, non-events, and so forth). The other one is:
	$$
	\begin{aligned}
		 E[cov(\delta_1, \delta_2)|C_1,C_2] = E\left\{ [\delta_1 - F_1(C_1)][\delta_2 - F_2(C_2)]  \right\}\\
	\end{aligned}
	$$
Which is \textbf{exactly} covariance of \textbf{PSR} for \emph{current status data}.

\subsection{Zhang, 2008: Inference on the association measure for bivariate survival data with hybrind censoring and applications to an HIV study, ref???}
The author uses archimedian copulas and Kendall's $\tau$ to assess association of bivariate survival data with hybrid censoring.

\subsection{P. Gaduthol Sankaran, B. Abraham, A Alphonsa Antony, 2006: A dependence measure for bivariate failure time data, ref???}
Meaning to improve over the measures given by Fan et al. (1998) and Fan et al. (2000), the authors propose a \emph{covariance residual life function} (CVRL) as a dependence measure of bivariate falure time data:
	$$
	\begin{aligned}
		 C(t_1, t_2) &= M(t_1, t_2) - r_1(t_1, t_2) r_2(t_1, t_2) =\\
		  &=E[(T_1-t_1)(T_2-t_2)|T_1>t_1,T_2>t_2] - E[T_1-t_1|T_1>t_1,T_2>t_2]\cdot E[T_2-t_2|T_1>t_1,T_2>t_2]
	\end{aligned}
	$$
They note that this measure is in fact a weighted average of the Clayton's $\theta(t_1,t_2) = \frac{S(t_1,t_2)D_1D_2(S(t_1,t_2))}{D(S(t_1,t_2))D_2(S(t_1,t_2))}$ with a weight $\left[ \frac{D_1D_2(S(t_1,t_2))}{D_1(S(t_1,t_2))D_2(S(t_1,t_2))} \right]^{-1}$.

\subsection{My plan}
\begin{enumerate}[1)]
  \item look at the papers that have PRS and see if they use covariates
  \item look at all papers that are marked with stars
	\item Look who cited Cuzick's paper
	\item look cited Alvo and Cabilio, 1993:
	\item look into Shih \& Louis, 1996: \emph{who sites those and what this is about (Louis is apparently known)}.
	\item Read the Cuzick's paper in detail.
	\item Look who cited Betensky, Filkenstein, AIDS, 1999: paper
Tests of independence for bivariate survival data:
	\item Understand Qi's conditional, partial, and conditional-partial correlation
	\item Find out about Spearman test (unlike Spearman's correlation)
	\item fFind all papers that cite Dabrowska's paper on correlation
	\item Develop Spearman correlation for different $s$ and $t$: instead of having one number $\rho$ develop a new measure $\rho(s, t)$.
\end{enumerate}


\section{Summary of: An Adjustment to Improve the Bivariate Survivor Function Repaired NPMLE. Moodie, Prentice, 2005 \cite{moodie2005adjustment}}

\subsection{Clayton, 1978 \cite{clayton1978model}}
Clayton suggested a \textit{a bivariate model for ordered pairs}. Suppose we are interested in onset of disease for fathers and sons. We want to know if they are associated. If $f(s,t)$ is a density of the age at which fathers ($t$) and sons ($s$) succomb to the disease, then the proposed model is:
	$$
	\begin{aligned}
		f(s,t)\int_s^{\infty}\int_t^{\infty} f(u, v)dvdu &= \theta \int_s^{\infty}f(u, t)du\int_t^{\infty}f(s, v)dv \\
	\end{aligned}
	$$
		or\\
	$$
	\begin{aligned}
		\theta &= \frac{f(s,t)\int_s^{\infty}\int_t^{\infty} f(u, v)dvdu} {\int_s^{\infty}f(u, t)du\int_t^{\infty}f(s, v)dv} = 
		\frac{ \frac{\partial^2 S(s, t)}{\partial s\partial t} \cdot S(s, t)}    {\frac{\partial S(s, t)}{\partial t} \frac{\partial S(s, t)}{\partial s}}
		&= \frac{f(s,t)/\frac{\partial S(s, t)}{\partial t}}  {\frac{\partial S(s, t)}{\partial s}/ S(s, t) } 
	\end{aligned}
	$$
We keep in mind that:
	$$
	\begin{aligned}
		f(s,t) &= &f(s|t)\cdot f(t)\\
		\frac{\partial S(s,t)}{\partial t} &= \int_s^{\infty}f(u, t)du = \int_s^{\infty}f(u|t)f_t(t)du = &S(s|t)\cdot f_t(t)\\
		\frac{\partial S(s,t)}{\partial s} &=...= S(t|s)\cdot f(s) = Pr(T>t|s)\cdot f(s) = Pr(T>t, s) = Pr(s,T>t) = Pr(s|T>t)S_t(t) = &f(s|T>t)\cdot S_t(t)\\
		S(s,t) &= Pr(S>s|T>t)\cdot Pr(T>t) = &S(s|T>t)\cdot S_t(t)
	\end{aligned}
	$$
By substituting these equations into the expression for $\theta$, we get:
	$$
	\begin{aligned}
		\theta &= \frac{f(s,t)/\frac{\partial S(s, t)}{\partial t}}  {\frac{\partial S(s, t)}{\partial s}/ S(s, t) } = \frac{  \frac{f(s|t)\cancel{f_t(t)}}{S(s|t)\cancel{f_t(t)}} } { \frac{f(s|T>t)\cdot \cancel{S_t(t)}}{S(s|T>t)\cdot \cancel{S_t(t)}}  }
		  = \frac{f(s|t)/S(s|t)}     {f(s|T>t) / S(s|T>t) }
		= \frac{\lambda_s(s|t) } {\lambda_s(s|T>t) }\\
	\end{aligned}
	$$
Because of the symmetry, we can write:
	$$
	\begin{aligned}
	  \theta = \frac{ \lambda_s(s_0|t=t_0)}{\lambda_s(s_0|t>t_0)} = \frac{ \lambda_t(t_0|s=s_0)}{\lambda_t(t_0|s>s_0)}
	\end{aligned}
	$$

The we have:
\begin{enumerate}[(i)]
	\item the joint survivor function:\\$\mathcal{F}(s, t) = \int_s^{\infty}\int_t^{\infty} f(u, v)dvdu$
	\item the hazard function for sons of fathers who survive until t, that is:\\
	$g(s;t) = \frac{\partial}{\partial s}\{log\mathcal{F}(s,t)\} = \frac{ \int_t^{\infty} f(s, v)dv} {\mathcal{F}(s, t)}$
	\item the hazard function for fathers of sons who survive until s, that is:\\
	$h(t;s) = \frac{\partial}{\partial t}\{log\mathcal{F}(s,t)\} = \frac{ \int_s^{\infty} f(u, t)du} {\mathcal{F}(s, t)}$
	\item the bivariate failure rate:\\
	$l(t;s) = \frac{f(s,t)}{\mathcal{F}(s,t)} = g(s;t) h(t;s) - \frac{ \partial^2 }{\partial s \partial t} \{-log\mathcal{F}(s,t)\}$
\end{enumerate}
After some complicated math, he derives:
	$$
	\begin{aligned}
		&\mathcal{F}(s,t) = [1 + (\theta - 1)\{a(s) + b(t)\}]^{-1/(\theta - 1)}\\
		&g(s;t) = \frac{a'(s)}{1 + (\theta - 1)\{a(s) + b(t)\}}\\
		&h(t;s) = \frac{b'(s)}{1 + (\theta - 1)\{a(s) + b(t)\}}\\
		&l(s,t) = \frac{\theta a'(s)b'(t)}{1+(\theta-1)(a(s) + b(t))^{2+1/(\theta-1)}}\\
		&f(s,t) = \frac{\theta a'(s)b'(t)}{1+(\theta-1)(a(s) + b(t))^{2}}
	\end{aligned}
	$$
Where $a(\cdot)$ and $b(\cdot)$ are nondecreasing (nuisance) functions with $a(0) = b(0)=0$.\\
\textbf{Interpretation:} when $\theta>1$, $g(s;t)$ is decreasing with respect to $t$ so that the age-specific rates for sons decrease with increased survival time of their fathers. Similarly, $h(t;s)$ decreases with respect to $s$. When $\theta=1$ and there is no asociation.\\
Parameter $\theta$ is estimated using maximum likelihood.

\subsection{Dabrowska, 1988 \cite{dabrowska1988kaplan}}
Dabrowska introduced defined a bivarate Kaplan-Meier estimator and proved its consistency (and probably something else). Her notations were used in the following papers:\\
Let $(\Omega, \mathcal{F}, P)$ be a probability space, and let $F(s,t) = P(T_1>s, T_2>t)$ be the corresponding joint survival function. By a bivariate cumulative hazard function, Dabrowska means a vector:
	$$
	\begin{aligned}
		\Lambda(s,t) &= (\Lambda_{10}(s,t), \Lambda_{01}(s,t), \Lambda_{11}(s,t))\\
		&where\\
		\Lambda_{11}(ds,dt) &= \frac{P(T_1 \in ds, T_2\in dt)}{P(T_1 \geq s, T_2 \geq t)} = \frac{F(ds, dt)}{F(s-, t-)}\\
		\Lambda_{10}(ds,t) &= \frac{P(T_1 \in ds, T_2 > dt)}{P(T_1 \geq ds, T_2 > t)} = \frac{-F(ds, t)}{F(s-, t)}~~~see ~the~paper~where ~it~is~F(s-, t-),~probably~a~typo\\ 
		\Lambda_{01}(s,dt) &= \frac{P(T_1 > s, T_2\in dt)}{P(T_1 > s, T_2 \geq t)} = \frac{-F(s, dt)}{F(s, t-)}\\
		&and\\
		\Lambda_{10}(0,t) &= \Lambda_{01}(s,0) = \Lambda_{11}(0,0) = 0\\
	\end{aligned}
	$$
If $F$ has a density $f(s,t)$, we have $\Lambda_{11}(ds,dt) = \lambda_{11}(s,t)ds~dt$, $\Lambda_{10}(ds,t) = \lambda_{10}(s,t)dt$, $\Lambda_{01}(s,dt) = \lambda_{01}(s,t)dt$, so

	$$
	\begin{aligned}
		\lambda_{11}(s,t) &= \lim_{(h_1,h_2)\rightarrow 0} \frac{1}{h_1 h_2} P(T_1\in[s,s+h_1], T_2\in[t,t+h_2] | T_1\geq s, T_2 \geq t) & = \frac{f(s,t)}{F(s-, t-)}\\
		\lambda_{10}(s,t) &= \lim_{h\rightarrow 0} \frac{1}{h} P(T_1\in[s,s+h] | T_1\geq s, T_2 > t) & = \int_t^{\infty} \frac{f(s,v)dv}{F(s-, t)}\\
		\lambda_{01}(s,t) &= \lim_{h\rightarrow 0} \frac{1}{h} P(T_2\in[t,t+h] | T_1 > s, T_2 \geq t) & = \int_s^{\infty} \frac{f(u,t)du}{F(s, t-)}\\
	\end{aligned}
	$$
Where $\lambda_{11}(s,t)$ is the instantaneous rate of \emph{double failure} at point $(s,t)$, given that the individuals were alive at times $T_1=s-$ and $T_2 = t-$. $\lambda_10(s, t)$ is the rate of a \emph{single failure} at time s give that the first individual was alive at time $T_1=s$ and the second survived beyond time $T_2 = 1$.\\

Long story short, he showed that a bivariate survival function can be decomposed into a product of two univariate components and some product of a function of bivariate hazards. He showed the consistency of the estimator (given independence of events and censoring), based on this decomposition:
	$$
	\begin{aligned}
		\hat{F}(s,t) = \hat{F}(s,0)\hat{F}(0,t)\prod_{\mathcal{A}}\{1 - \hat{L}(\Delta u, \Delta v)\}
	\end{aligned}
	$$
Where 
\begin{itemize}
	\item $\mathcal{A} = \{0<u\leq s\} \cap \{0 < v \leq t\} \cap \{(u, v) \in E_i\}$, where $E_i$ are four sets based on \emph{Jordan decomposition of functions with bounded variation}, and $\hat{L}(\Delta u, \Delta v)$ is a function of hazards (see the source).
  \item $\hat{F}(s,0)$ and $\hat{F}(0,t)$ are usual Kaplan-Meier estimates, for example, $\hat{F}(s,0) = \prod_{u\leq s}[1-\hat{\Lambda_{10}(\Delta u, o)}]$
	\item $\hat{L}(\Delta u, \Delta v) = \frac{\hat{\Lambda}_{10}(\Delta u,v^-)\hat{\Lambda}_{01}(u^-,\Delta v) - \hat{\Lambda}_{11}(\Delta u,\Delta v)}{\left(1-\hat{\Lambda}_{10}(\Delta u,v^-)\right)\left(1-\hat{\Lambda}_{01}(u^-,\Delta v)\right)}$
\end{itemize}

 \subsection{Pruitt, 1991 \cite{pruitt1991negative}}
 Pruitt showed that Dabrowska's estimator assigns negative mass to points of $\hat{F}(s,t)$. Although the value of negative mass decreases, the number of such points does not disappear with growing sample size, resulting in non-disappearing negative mass.\\
This problem is related to the problem of identifiability of bivariate survival functions.


 \subsection{Oakes, 1989 \cite{oakes1989bivariate}}
 Oakes studied association between two survival functions in the context of \emph{frailty} models $Pr(T>t|W=w) = \{B(t)\}^w$. It can be shown that for these models:
	$$
	\begin{aligned}
		S(t) &= Pr(T>t) = E_W[Pr(T>t,w)] = \int Pr(T>t|w)dF{w} = E_W[B^w(t)] = \\
		  &=E_W e^{-(-logB(t))w} = p(-logB(t))
	\end{aligned}
	$$
 where $p(\cdot)$ is the Laplace transform of $W$ ($p(x) = Ee^{xW}$). This representation extends for bivariate distributions, $S(t_1, t_2) = Pr(T_1>t_1, T_2>t_2)$. ''A bivariate frailty model asserts that T, and T2 are conditionally independent, given W:''
	$$
	\begin{aligned}
		S(t_1, t_2) &= \int \{B_1(t_1)B_2(t_2)\}^w dF(w)\\
		& therefore:\\
		S(t_1, t_2) &= p(-logB_1(t_1)-logB_2(t_2))
	\end{aligned}
	$$
	Oakes shows that when each $S_j(t_j)$ depends on the unobserved $W$ this induces an association between the observed times. He also notes that bivariate distributions generated by frailty models are a subclass of the archimedean distributions studied by Genest and MacKay (1986a,b) with the following general form. In the following we use the following notation $t=(t_1, t_2)$\\
	$$
	\begin{aligned}
		S(t) &= p[q(S_1\{t_1\}) + q(S_2\{t_2\})],~~~~~S_1(t_1) = S_1(t_1, 0)~~and~~S_2(t_2) = S_2(0, t_2)
	\end{aligned}
	$$
Where $p(\cdot)$ is any nonnegative decreasing function with $p(0)=1$ and nonnegative second derivative, and $q(\cdot)$ is its inverse function. Recalling Clayton's formula for $\theta$:
	$$
	\begin{aligned}
		\theta &= \frac{ \frac{\partial^2 S(s,t)}{\partial s \partial t} S(s, t)}    {\frac{\partial S(s, t)}{\partial t} \frac{\partial S(s, t)}{\partial s}}
	\end{aligned}
	$$
Oakes proves a lemma that to make a point that $\theta$ depends on $t$ only through $S(t)=v$ $\theta(v) = \theta^*(t) = \theta^*(S(t))$, (keep in mind that $t$ is a vector). He derives a general formula for $\theta(v)$:
	$$
	\begin{aligned}
		\theta(v) = -v\cdot q''(v)/q'(v)
	\end{aligned}
	$$
He also shows how to find $S(t)$ based on $\theta(v)$. He gives several examples of how to find one from the other.


	
{\tiny{\textbf{We recall Kendal's $\tau$, 1938 \cite{kendall1938new}}: If we have two independent paris of variables (with the same bivariate distribution) $(U_1, Z_1)$ and $(U_2, Z_2)$, Kendal's $\tau$ is a probability of concordance minus probability of discordance:
$\tau = P[(U_1 - U_2)(Z_1 - Z_2)>0] - P[(U_1 - U_2)(Z_1 - Z_2)<0] = E[sign((U_1 - U_2)(Z_1 - Z_2))]$}}

 
In notations of Oakes, Kendall's (1938) coefficient of concordance is:
	$$
	\begin{aligned}
		&\tau = E\{sign(T_{1}^{(a)} - T_{1}^{(b)}) (T_{2}^{(a)} - T_{2}^{(b)}) \}
	\end{aligned}
	$$
	Where $(T_1^{(a)}, T_2^{(a)})$ and $(T_1^{(b)}, T_2^{(b)})$ are two independent pairs (for example, if we study mothers (1) and daughers (2), $(T_1^{(a)}, T_2^{(a)})$ is one mother-daughter pair and $(T_1^{(b)}, T_2^{(b)})$ is the other).\\

 Oakes called $\tau$ a \emph{global} measure. He also said that parameter $\theta$ (introduced by Clayton) can be viewed as \emph{local} measure. If $T^{(a)}=(T_1^{(a)}, T_2^{(a)})$ and $T^{(b)} = (T_1^{(b)}, T_2^{(b)})$, let $\tilde{T}^{(ab)}$ denote the component-wise minimum: $\tilde{T}^{(ab)}_j = min(T^{(a)}_j, T^{(b)}_j),~j\in\{1,2\}$, then (Oakes says that \emph{it is easily seen}):
	$$
	\begin{aligned}
		\theta(v) = \frac{Pr\{(T^{(a)}, T^{(b)})~concordant|\tilde{T}^{(ab)}=t\} }{  Pr\{(T^{(a)}, T^{(b)})~discordant|\tilde{T}^{(ab)}=t\}}
 	\end{aligned}
	$$
Therefore, the ratio $\frac{\theta(v)-1}{\theta(v)+1}$ is a conditional version of Kendall's $\tau$.
	$$
	\begin{aligned}
		&\tau(v) = E\{sign(T_{1}^{(a)} - T_{1}^{(b)}) (T_{2}^{(a)} - T_{2}^{(b)}) ~|~ min(T^{(a)}_1, T^{(b)}_1) = s_1,~min(T^{(a)}_2, T^{(b)}_2) = s_2  \}
	\end{aligned}
	$$
He comes up with an estimator and proves its convergence to $\theta(v)$.

\subsection{Cuzick, 1982 citation ?????}
Considers a general model of association:
	$$
	\begin{aligned}
		Y_1 = aZ + e_1 ~~~~~~~~ Y_2 = bZ + e_2
	\end{aligned}
	$$
Where $Z$, $e_1$, and $e_2$ are independent. He considers two cases, and only the second case is relevant for us, when $b=a\lambda,~~0<|\lambda|<\infty$. In this case two variables $(Y_1, Y_2)$ are thought to be related to a third unobserved covariate.\\
It is not very clear from the paper what they denote as $f_i(x)$. I am guessing this is a density of $Y_i$ (or of $e_i$?). In any case, they author says that when this density is logistic, $f(x) = 2\pi_{-1} e^{-x}/(1+e^{-x})^2$, then the rank of each observation is $F(x)$ with no censoring, and $\frac{1+F(x)}{2}$, when censoring is present.

\subsection{Shih and Louis, 1998 citation ?????}
They take martingale residuals $T_n=\sum_i \int_0^{t_0}  \int_0^{t_0} d\hat{M}_{i1}(u_1) d\hat{M}_{i2}(u_2)$ (where $M_{ij}$ is the difference between observed and expected deaths), and create two statistics out of them:
\begin{enumerate}
	\item take supremum: $U_n= \sup_{0\leq t \leq t_0} \left|\sum_i \int_0^{t_0}  \int_0^{t_0} d\hat{M}_{i1}(u_1) d\hat{M}_{i2}(u_2)\right|$
	\item weigh it: $V_n= \sum_i \int_0^{t_0}  \int_0^{t_0} W_n(u_1,u_2) d\hat{M}_{i1}(u_1) d\hat{M}_{i2}(u_2)$ (which is analogous to the weighted logrank test)
\end{enumerate}
They choose \emph{optimal} weights by somehow using the \emph{cross ratio} defined by Oakes $\theta = \frac{ \frac{\partial^2 S(s,t)}{\partial s \partial t} S(s, t)}    {\frac{\partial S(s, t)}{\partial t} \frac{\partial S(s, t)}{\partial s}}$: 

\subsection{Alvo and Cabilio, 1995 citation ?????}
UNDER CONSTRUCTION.\\
The authors use a concept of distance applied to \emph{Spearman} and \emph{Kendal} correlation measure in order to build a test that can deal with missing data. 

\subsection{Fan, 1998 \cite{fan2000dependence}}
There is a need in non-parametric measure of association between two survival times.\\
Clayton suggested a \textit{cross ratio} (Clayton, 1978, Oaks, 1989) (see Clayton's $\theta$):
	$$
	\begin{aligned}
		&\tilde{c}(s_1, s_2) = \frac{F(ds_1, ds_2)F(ds_1^-, ds_2^-)} {F(ds_1, ds_2^-)F(ds_1^-, ds_2)} \\
		 &or\\
		 & \tilde{c}(s_1, s_2) = \frac{ \lambda_1(s_1|T_2=s_2)}{\lambda_1(s_1|T_2 \geq s_2)} = \frac{ \lambda_2(s_2|T_1=s_1)}{\lambda_2(s_2|T_1 \geq s_1)}
	\end{aligned}
	$$
Which $\left(\frac{ \lambda_2(s_2|T_1=s_1)}{\lambda_2(s_2|T_1 \geq s_1)}\right)$ can be interpreted as ''the ratio of the breast cancer risk for daughters of age $s_2$ whose mothers developed breast cancer at age $s_1$, compared to daughters of age $s_2$ whose mothers were breast cancer free to age $s_1$. This type of hazard ratio, or relative risk, is most familiar to epidemiologists, and an average relative risk over a range of ages may be readily interpreted and meaningful in epidemiologic contexts''.\\

''Following the suggestion of in Hsu and Prentice (1996) one could consider a summary dependence measure that weights the cross ratio $\tilde{c}(s_1, s_2)$ over $[0, t_1]\times[0, t_2]$ by $\frac{F(ds_1,ds_2)}{\int_0^{t_1}\int_0^{t_2} F(du_1, du_2)}$''. But there are some problems with consistency of $\tilde{c}(s_1, s_2)$ when it is weighted this way.\\
Instead, the authors propose to weight $c(s_1, s_2) = \frac{1}{\tilde{c}(s_1, s_2)}$ and get:
	$$
	\begin{aligned}
		C(t_1, t_2) &= \int_0^{t_1}\int_0^{t_2} \frac{c(s_1, s_2)F(ds_1,ds_2)}{\int_0^{t_1}\int_0^{t_2} F(du_1, du_2)} =\int_0^{t_1}\int_0^{t_2} \frac{F(ds_1, ds_2^-)F(ds_1^-, ds_2)} {\cancel{F(ds_1, ds_2)}F(ds_1^-, ds_2^-)} \frac{\cancel{F(ds_1,ds_2)}}{\int_0^{t_1}\int_0^{t_2} F(du_1, du_2)} = \\
		&= \int_0^{t_1}\int_0^{t_2} \frac{F(ds_1, ds_2^-)F(ds_1^-, ds_2)} {F(ds_1^-, ds_2^-)} \frac{1}{\int_0^{t_1}\int_0^{t_2} F(du_1, du_2)} \frac{F(ds_1^-, ds_2^-)}{F(ds_1^-, ds_2^-)}= \\
		&= \int_0^{t_1}\int_0^{t_2} \frac{F(ds_1^-, ds_2^-)\Lambda_{10}(ds_1, s^-_2)\Lambda_{01}(s^-_1, ds_2)}{\int_0^{t_1}\int_0^{t_2} F(du_1, du_2)} = \\
	\end{aligned}
	$$
	Because $F(\cdot, \cdot)$ is a survival function, our denominator is:
	$$
	\begin{aligned}
		\int_0^{t_1}\int_0^{t_2} F(du_1, du_2) &= \int_0^{t_2} [F(t_1, du_2) - F(0, du_2)]= F(t_1, t_2) - F(t_1, 0) - F(0, t_2) + F(0,0)=\\
		&=1 - F(t_1, 0) - F(0, t_2)+ F(t_1, t_2)\\
	\end{aligned}
	$$
	So
	$$
	\begin{aligned}
		C(t_1, t_2) &= \int_0^{t_1}\int_0^{t_2} \frac{F(ds_1^-, ds_2^-)\Lambda_{10}(ds_1, s^-_2)\Lambda_{01}(s^-_1, ds_2)}{1 - F(t_1, 0) - F(0, t_2)+ F(t_1, t_2)} \\
	\end{aligned}
	$$
	When $C(t_1, t_2)>1$, there is positive association. When $C(t_1, t_2)=1$, there is no association. When $C(t_1, t_2)<1$, there is negative association.  \\
	In addition to $C(t_1, t_2)$ they proposed another summary measure of dependence inspired by Oakes, 1989 \cite{oakes1989bivariate} who proposed (we are using notations of Fan, 1998 \cite{fan2000dependence}):
	$$
	\begin{aligned}
		&\tau(s_1, s_2) = E\{sign(T_{11} - T_{12}) (T_{21} - T_{22})~|~ T_{11}\wedge T_{12} = s_1,~T_{21}\wedge T_{22} = s_2  \}
		&~~~~where~\wedge~is~minimum
	\end{aligned}
	$$

	Oakes also noted that $\tau(s_1, s_2)$ can be written as:
	$$
	\begin{aligned}
		\tau(s_1, s_2) &= \frac{1 - c(s_1, s_2)}{1+c(s_1, s_2)}
	\end{aligned}
	$$
The authors propose to weight this $\tau(s_1, s_2)$ proportionally to the density. After some algebra, it can be shown that the weighted $\tau$ (denoted as $\mathcal{T}(t_1, t_2)$) can be written as:
	$$
	\begin{aligned}
		&\mathcal{T}(t_1, t_2) = E\{sign(T_{11} - T_{12}) (T_{21} - T_{22})~|~ T_{11}\wedge T_{12} \leq t_1,~T_{21}\wedge T_{22} \leq t_2  \}
	\end{aligned}
	$$
	so that $\mathcal{T}(t_1, t_2) \in [-1,1]$

\subsection{Prentice, 1992 \cite{prentice1992covariance}}
???
% If I understand correctly, the authors model bivariate survival as two marginal survivor functions and a covariance function (instead of joint survivor function).

\subsection{Fan, 2000 \cite{fan2000class}}
The authors suggest a class of estimators similar to what was described in \emph{Fan, 1998} \cite{fan2000dependence}, which were weighted averages of local measures. The motivation for new estimators was that ''for certain choices of weights, the estimation of the bivariate survivor function (e.g. Dabrowska (1998)\cite{dabrowska1988kaplan} and Prentice and Cai (1992) \cite{prentice1992covariance}), can be avoided and explicit variance formulae can be obtained.''\\
The authors utilize the fact that both $C(\cdot, \cdot)$ and $\mathcal{T}(\cdot, \cdot)$ depend on $F(\cdot, \cdot)$ only through the hazard function and therefore can be estimated using Nelson-Aalan-type estimator of the hazard:

	$$
	\begin{aligned}
    C(t_1, t_2) &= \frac{\int_0^{t_1}\int_0^{t_1} H_{11}(ds_1, ds_2)}{\int_0^{t_1}\int_0^{t_1} H_{10}(ds_1, s_2^-)H_{01}(s_1^-, ds_2)}\\
    \mathcal{T}(t_1, t_2) &= \frac{\int_0^{t_1}\int_0^{t_1} H_{11}(ds_1, ds_2) - \int_0^{t_1}\int_0^{t_1} H_{10}(ds_1, s_2^-)H_{01}(s_1^-, ds_2) }{\int_0^{t_1}\int_0^{t_1} H_{11}(ds_1, ds_2) + \int_0^{t_1}\int_0^{t_1} H_{10}(ds_1, s_2^-)H_{01}(s_1^-, ds_2) }\\
	\end{aligned}
	$$

\subsection{van der Laan, 1997 \cite{van1997nonparametric}}
The estimators of Dabrowska and Prentice and Cai:
	$$
	\begin{aligned}
    S(t_1, t_2) &= S_1(t_1)S_2(t_2)R(t_1, t_2);\\
		R(t_1, t_2) &= \frac{S(t_1, t_2)S(0, 0)}{S(t_1)S(t_2)}
 	\end{aligned}
	$$
where $R(t_1, t_2)$ is called \emph{a cross-ratio}(I think) and is a dependence measure between events $T_1>t_1$ and $T_2>t_2$, and $S_j(t_j)$ is a marginal survivor function that is estimated using Kaplan-Meier estimator. The cross-ratio has ''multiplicative property: the cross-ratio over the union of two adjacent rectangles equals the product of the cross-ratios of the rectangles.'' It can be computed iteratively, which leads to the Dbrowska estimator.\\
\\
If we represent $R(t_1, t_2) = e^{log(R(t_1, t_2))}$, then $log(R)$ is  an additive measure over the rectangle $(0,s_1]\times(0,s_2]$ and we can compute:
	
	$$
	\begin{aligned}
		log(R)(t_1, t_2) &= \int_{(0,t_1]\times(0,t_2]} d~log(R)(s_1,s_2)
 	\end{aligned}
	$$

There is a problem (with consistency) with finding these estimators for continuous using EM algorithm because we need to redistribute the mass and there is a problem with it for singly censored observations. This problem was corrected by Pruitt(1991) by using kernel-density estimators. Van der Laan proposed NPMLE based on interval censored singly-censored observations.\\
\\
Under complete independence of events and censoring events, Dabrowska's and Prentice and Cai's estimators did better. With increased dependence, Laan's estimator did better.
	
\printbibliography

\end{document}          

