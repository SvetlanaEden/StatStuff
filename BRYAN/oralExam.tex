\documentclass[]{article}

\usepackage{anysize}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{enumerate}
\usepackage{cancel}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{color}

%%% for citations. See Lucy's tutorial: https://github.com/LucyMcGowan/Tutorials/blob/master/BiblatexTutorial.md
\usepackage[backend=biber,maxnames=10,citestyle=science]{biblatex}
\addbibresource{summaryOfRef.bib}

%%% when using biber as a "backend" compile like this:
% pdflatex myFile
% biber myFile
% pdflatex myFile


\let\epsilon\varepsilon
\newcommand\SLASH{\char`\\}
\newcommand{\csch}{\text{csch}}
\marginsize{0.5in}{1in}{0.5in}{1in}
\setlength\parindent{0pt}

% Title Page: Modify as needed
\title{Summary for Bryan's research}
\author{Summarized by Svetlana Eden}
\date{Month Day, 2015}

\hypersetup{hidelinks}

% \usepackage[pdftex,bookmarks,pagebackref,pdfpagemode=UseOutlines,
%      colorlinks,linkcolor=\linkcol,
%      pdfauthor={Svetlana K Eden},
%      pdftitle={\titl}]{hyperref}


\begin{document}
\maketitle
\tableofcontents
\listoffigures
\listoftables
\clearpage

\section{Introduction}
The interest in survival outcome can be traced back to year 1846, when a Hungarian doctor of the Vienna General Hospital maternity clinic, Ignaz Semmelweis, collected data on the rate of death from childbed fever. He hypothesized that a child birth is helped by a doctor or a medical student, the women's rate of death from childbed fever is higher because of a disease that is caused by cadaverous particles that medical students and doctors have on on their hands after disecting cadavras. Jumping forward about 100 years, survival data was routinely collected and used by hospital, agencies, and governments [READ YOUR epidemiology book]. The recorded data were used to estimate rates of death and other events.

Hald in 1949 ["Maximum Likelihood estimation of th eparameters of a normal distribution which is trancated at a known point", \emph{Skandinavisk Aktuarielidskrift, 32 (1949)}, 119-134], suggested a more complex view of survival data and introduced a concept of censoring. This concept elegantly taken into accout by one of the most famous work on survival, Kaplan and Meier [1958, p.459]. Cox (1972) extended Kaplan\&Meier results even further and introduced a regression model for censored suvival data. His model utilized a concept of a \emph{hazard rate}:
$$
\begin{aligned}
	\lambda(s|y) &= \frac{\partial}{\partial s}\left\{  -log \mathcal{S}(s|y)  \right\} =
	             \frac{f(s|y)}{\mathcal{S}(s|y)}
\end{aligned}
$$
Where $\mathcal{S}(s|y) = 1-F(s|y)$, and $F(s|y)$ and $f(s|y)$ are cumulative distribution function and density function respectively. In the same paper (p.195) he also generalized his model for a case when one subject can have two events.\\
Unlike Cox, Basu (1971) [get this paper from the library ??? this does not add up because Cox wrote his paper later] considered a \emph{paired} bivariate survival with the hazard rate defined as:
$$
\begin{aligned}
	\lambda(s,t) &= \frac{f(s,t)}{\mathcal{S}(s,t)} = \frac{\partial}{\partial s}\left\{  -log \mathcal{S}(s,t)  \right\}\frac{\partial}{\partial t}\left\{  -log \mathcal{S}(s,t)  \right\} - \frac{\partial^2}{\partial s\partial t}\left\{  -log \mathcal{S}(s,t)  \right\}
\end{aligned}
$$

\subsection{Different directions of research}
The question of association was addressed using different modeling approaches. First, this question was formulated for a specific survival distribution. Then, it was generalized to a family of distributions. Then, an attempted was made to find a non-paramtric estimate of the bivariate survival function that was estimated as two marginal survival functions and a term that represented the association between two survivals. Other approaches included, but were  not limited to: association of martingale residual, modeling association term using copulas, bootstrap, and also developing linear rank tests approximations. Even in the context of linear rank test, some assumptions about the distribution of survival time was necessary. We finish the overview of this topic with explaining a non-parametric approach to this problem, \emph{probability scale residuals} [ref???].




\subsection{Modeling a bi-variate hazard ratio}

\subsubsection{Clayton, 1978}
Later in 1978, Clayton [???] addressed a question of association between paired survival times of fathers and sons and defined a measure similar to harzard ratio. He wanted this measure to be
\begin{enumerate}
	\item  easy to compute
	\item expressible as a constant ratio of age-specific rates
  \item symmetrical in two variables
\end{enumerate}
If we denote time to event for fathers to be $s$ and time to event for sons to be $t$, this measure can be written in the following way:
$$
\begin{aligned}
	\theta = \frac{\lambda_s(s_0|t=t_0)}{\lambda_s(s_0|t>t_0)} = \frac{\lambda_t(t_0|s=s_0)}{\lambda_t(t_0|s>s_0)}
\end{aligned}
$$
The requirement of symmetry is motivated by the fact than neither son nor father are causes of event, rather, there is an unobservable variable that is associated with the event for both of them.

This measure can be interpreted for sons (as much as for fathers) in the following way: how much more likely for a son to have an event at time $s_0$ given that his father had an event at time $t_0$ compared to a son whose father survived until time $t_0$ without the event.

Independence between fathers and sons would mean $\theta = 1$, positive association $\theta > 1$ and negative association $\theta < 1$. Clayton also explained how his model could be generalized to include covariates, and in estimating the model he adopts an approach similar to Cox's. He also derived likelihood for estimating $\theta$ when two marginal distributions are completely unknown.\\

Note that although Clayton developed $\theta$ in the context of a model, the model was not necessacery to check independence. Independence could be checked by evaluating $\theta$.\\

\subsubsection{Oakes, 1982, 1989}
Oakes (1982 ???) criticised Clayton's likelihood approach to estimating $\theta$ and introduced an alternative method based on \emph{Kendall}'s $\tau$, coefficient of concordance. Furter in 1989, he introduced a bivariate survival model based on \emph{frailties}. The concept of \emph{frailties} implied that if two survival times depend on an unobserved variable, this induces dependence between the variable themselves. In the context of this model, he further developed coefficient $\theta$ introduced by Clayton. He also noted that bivariate distributions introduced by frailty models are part of a larger class of archimedian distributions studied by Genest and MacKay (1986a,b ???):
$$
\begin{aligned}
	S(t) = p\left[ q\left\{ S_1(t_1) \right\}  + q\left\{ S_2(t_2) \right\}  \right]
\end{aligned}
$$
Where $p(u)$ is an inverse function of $q(v)$. He showed how to estimate his model in the presence of censoring of one or both components. He showed that in the context of his model, $\theta$ and \emph{Kendall}'s $\tau$ were related through the following equality: $ \frac{\theta(v)-1}{\theta(v)+1} = \tau(v)$, where $v=S(t_1, t_2)$.
{\tiny{\textbf{We recall Kendal's $\tau$, 1938 \cite{kendall1938new}}: If we have two independent paris of variables (with the same bivariate distribution) $(U_1, Z_1)$ and $(U_2, Z_2)$, Kendal's $\tau$ is a probability of concordance minus probability of discordance:
$\tau = P[(U_1 - U_2)(Z_1 - Z_2)>0] - P[(U_1 - U_2)(Z_1 - Z_2)<0] = E[sign((U_1 - U_2)(Z_1 - Z_2))]$}}

\subsubsection{Fan, Hsu, Prentice, 1998 \cite{fan2000dependence}}
The authors wanted to develop a measure of association that would make sense in the finite region (mothers of ages 50-80, daughters of ages 30-60) and in the presence of independent right censoring. They considered a weighted average of Clayton's \textit{cross ratio} $\theta$ over $[0,t_1] \times [0, t_2]$, $\theta = \frac{ \lambda_2(s_2|T_1=s_1)}{\lambda_2(s_2|T_1 \geq s_1)}$. As a reminder, it can be interpreted as a risk for daughters of age $s_2$ whose mothers developed a disease at age $s_1$, compared to daughters of age $s_2$ whose mothers were disease free at age $s_1$''.\\ They made a point that in order to increase interpretability and comparability accross studies, the weighting should be independent of censoring mechanizm.

They allowed the time to be discrete, continuous, or mixed, but $F(., .)$ was required to possess a density relative to the corresponding counting Lebesque measure.

It made sense to weight the cross ratio $\tilde{c}(s_1, s_2)$ over $[0, t_1]\times[0, t_2]$ by $\frac{F(ds_1,ds_2)}{\int_0^{t_1}\int_0^{t_2} F(du_1, du_2)}$. But this would have resulted in inconsistent estimator.\\
Instead, the authors proposed to weight $c(s_1, s_2) = \frac{1}{\tilde{c}(s_1, s_2)}$ and get:
	$$
	\begin{aligned}
		C(t_1, t_2) &= \int_0^{t_1}\int_0^{t_2} \frac{c(s_1, s_2)F(ds_1,ds_2)}{\int_0^{t_1}\int_0^{t_2} F(du_1, du_2)} = ...= \int_0^{t_1}\int_0^{t_2} \frac{F(s_1^-, s_2^-)\Lambda_{10}(ds_1, s^-_2)\Lambda_{01}(s^-_1, ds_2)}{1 - F(t_1, 0) - F(0, t_2)+ F(t_1, t_2)} \\
	\end{aligned}
	$$
	Which can be estimated non-parametrically using $\hat{F}$ of Dabrowska [1988] or Prentice and Cai [1992], and $\hat{\Lambda}$ can be estimated using Nelson-Aalen estimator.
	Note that $C(t_1, t_2)$ may be interpreted as a relative risk: when $C(t_1, t_2)>1$, there is positive association. When $C(t_1, t_2)=1$, there is no association. When $C(t_1, t_2)<1$, there is negative association. It can also be interpreted as a weighted average hazard ratio with weights proportional to the failure time density at $(s_1,s_2)$. (Say about negative mass issue).\\
Because Oakes[1989??? \cite{oakes1989bivariate}] noted that $\tau(s_1, s_2)$ can be written as:
	$$
	\begin{aligned}
		\tau(s_1, s_2) &= \frac{1 - c(s_1, s_2)}{1+c(s_1, s_2)}
	\end{aligned}
	$$
	the authors proposed another summary measure of association:
	$$
	\begin{aligned}
		&\tau(s_1, s_2) = E\{sign(T_{11} - T_{12}) (T_{21} - T_{22})~|~ T_{11}\wedge T_{12} = s_1,~T_{21}\wedge T_{22} = s_2  \}
		&~~~~where~\wedge~is~minimum
	\end{aligned}
	$$

After weighing this $\tau(s_1, s_2)$ proportionally to the density, they obtain the weighted $\tau$ (denoted as $\mathcal{T}(t_1, t_2)$):
	$$
	\begin{aligned}
		&\mathcal{T}(t_1, t_2) = E\{sign(T_{11} - T_{12}) (T_{21} - T_{22})~|~ T_{11}\wedge T_{12} \leq t_1,~T_{21}\wedge T_{22} \leq t_2  \}
	\end{aligned}
	$$
	so that $\mathcal{T}(t_1, t_2) \in [-1,1]$
	
Both, $C(t_1, t_2)$ and $\mathcal{T}(t_1, t_2)$ were proven to be strongly consistent (definition ?), converged in distribution to a mean zero Gaussian process and had a property of assimptotic validity (defintion ?) of the boostrap.

\subsection{Fan, 2000 \cite{fan2000class}}
The authors suggest a class of estimators similar to what was described in \emph{Fan, 1998} \cite{fan2000dependence}, which were weighted averages of local measures. The motivation for new estimators was that ''for certain choices of weights, the estimation of the bivariate survivor function (e.g. Dabrowska (1998)\cite{dabrowska1988kaplan} and Prentice and Cai (1992) \cite{prentice1992covariance}), can be avoided and explicit variance formulae can be obtained.''\\
The authors utilize the fact that in some specific cases, both $C(\cdot, \cdot)$ and $\mathcal{T}(\cdot, \cdot)$ depend on $F(\cdot, \cdot)$ only through the hazard function and therefore can be estimated using Nelson-Aalan-type estimator of the hazard:

	$$
	\begin{aligned}
    C(t_1, t_2) &= \frac{\int_0^{t_1}\int_0^{t_1} H_{11}(ds_1, ds_2)}{\int_0^{t_1}\int_0^{t_1} H_{10}(ds_1, s_2^-)H_{01}(s_1^-, ds_2)}\\
    \mathcal{T}(t_1, t_2) &= \frac{\int_0^{t_1}\int_0^{t_1} H_{11}(ds_1, ds_2) - \int_0^{t_1}\int_0^{t_1} H_{10}(ds_1, s_2^-)H_{01}(s_1^-, ds_2) }{\int_0^{t_1}\int_0^{t_1} H_{11}(ds_1, ds_2) + \int_0^{t_1}\int_0^{t_1} H_{10}(ds_1, s_2^-)H_{01}(s_1^-, ds_2) }\\
	\end{aligned}
	$$





\subsection{Estimating bivariate survival surface}

\subsubsection{Dabrowska, 1988 \cite{dabrowska1988kaplan}}
Dabrowska introduced defined a bivarate Kaplan-Meier estimator and proved its consistency (and probably something else). Her notations were used in the following papers:\\
Let $(\Omega, \mathcal{F}, P)$ be a probability space, and let $F(s,t) = P(T_1>s, T_2>t)$ be the corresponding joint survival function. By a bivariate cumulative hazard function, Dabrowska means a vector:
	$$
	\begin{aligned}
		\Lambda(s,t) &= (\Lambda_{10}(s,t), \Lambda_{01}(s,t), \Lambda_{11}(s,t))\\
		&where\\
		\Lambda_{11}(ds,dt) &= \frac{P(T_1 \in ds, T_2\in dt)}{P(T_1 \geq s, T_2 \geq t)} = \frac{F(ds, dt)}{F(s-, t-)}\\
		\Lambda_{10}(ds,t) &= \frac{P(T_1 \in ds, T_2 > dt)}{P(T_1 \geq ds, T_2 > t)} = \frac{-F(ds, t)}{F(s-, t)}~~~see ~the~paper~where ~it~is~F(s-, t-),~probably~a~typo\\ 
		\Lambda_{01}(s,dt) &= \frac{P(T_1 > s, T_2\in dt)}{P(T_1 > s, T_2 \geq t)} = \frac{-F(s, dt)}{F(s, t-)}\\
		&and\\
		\Lambda_{10}(0,t) &= \Lambda_{01}(s,0) = \Lambda_{11}(0,0) = 0\\
	\end{aligned}
	$$
If $F$ has a density $f(s,t)$, we have $\Lambda_{11}(ds,dt) = \lambda_{11}(s,t)ds~dt$, $\Lambda_{10}(ds,t) = \lambda_{10}(s,t)dt$, $\Lambda_{01}(s,dt) = \lambda_{01}(s,t)dt$, so

	$$
	\begin{aligned}
		\lambda_{11}(s,t) &= \lim_{(h_1,h_2)\rightarrow 0} \frac{1}{h_1 h_2} P(T_1\in[s,s+h_1], T_2\in[t,t+h_2] | T_1\geq s, T_2 \geq t) & = \frac{f(s,t)}{F(s-, t-)}\\
		\lambda_{10}(s,t) &= \lim_{h\rightarrow 0} \frac{1}{h} P(T_1\in[s,s+h] | T_1\geq s, T_2 > t) & = \int_t^{\infty} \frac{f(s,v)dv}{F(s-, t)}\\
		\lambda_{01}(s,t) &= \lim_{h\rightarrow 0} \frac{1}{h} P(T_2\in[t,t+h] | T_1 > s, T_2 \geq t) & = \int_s^{\infty} \frac{f(u,t)du}{F(s, t-)}\\
	\end{aligned}
	$$
Where $\lambda_{11}(s,t)$ is the instantaneous rate of \emph{double failure} at point $(s,t)$, given that the individuals were alive at times $T_1=s-$ and $T_2 = t-$. $\lambda_{10}(s, t)$ is the rate of a \emph{single failure} at time s give that the first individual was alive at time $T_1=s$ and the second survived beyond time $T_2 = 1$.\\

Long story short, he showed that a bivariate survival function can be decomposed into a product of two univariate components and some product of a function of bivariate hazards. She showed the consistency of the estimator (given independence of events and censoring), based on this decomposition:
	$$
	\begin{aligned}
		\hat{F}(s,t) &= \hat{F}(s,0)\hat{F}(0,t)\cdot \prod_{{0<u\leq s~0<v\leq t}}\{1 - \hat{L}(\Delta u, \Delta v)\}\\
	\end{aligned}
	$$
Where $\hat{F}(s,0)$ and $\hat{F}(0,t)$ are usual Kaplan-Meier estimates, for example, $\hat{F}(s,0) = \prod_{u\leq s}[1-\hat{\Lambda_{10}(\Delta u, o)}]$, and
	$$
	\begin{aligned}
    \hat{L}(\Delta u, \Delta v) &= \frac{\hat{\Lambda}_{10}(\Delta u,v^-)\hat{\Lambda}_{01}(u^-,\Delta v) - \hat{\Lambda}_{11}(\Delta u,\Delta v)}{\left(1-\hat{\Lambda}_{10}(\Delta u,v^-)\right)\left(1-\hat{\Lambda}_{01}(u^-,\Delta v)\right)}\\
  &where\\
	&\hat{\Lambda}(\Delta t_1, \Delta t_2) = \#(T_1=t_1, T_2=t_2, \delta_1=\delta_2=1)/\#(T_1\geq t_1, T_2\geq t_2)\\
	&\hat{\Lambda}_{10}(\Delta t_1, t_2^-) = \#(T_1=t_1, \delta_1=1, T_2\geq t_2)/\#(T_1\geq t_1, T_2\geq t_2)\\
	&\hat{\Lambda}_{01}(t_1^-,\Delta  t_2) = \#(T_2=t_2, \delta_2=1, T_1\geq t_1)/\#(T_1\geq t_1, T_2\geq t_2)		
	\end{aligned}
	$$
It is possible to show that expression $1-L(du, dv)$ can be written as:
	$$
	\begin{aligned}
		1 - L(du, dv) &= \frac{P(T_1>u,~T_2>v|T_1\geq u,~T_2\geq v)}  {P(T_1>u|T_1\geq u,~T_2\geq v)P(T_2>v|T_1\geq u,~T_2\geq v)} =
		\frac{ F(u,v)F(u-,v-) }{ F(u,v-)F(u-,v) }
	\end{aligned}
	$$

Which looks very much like:
	$$
	\begin{aligned}
		\theta &= \frac{ \frac{\partial^2 S(s,t)}{\partial s \partial t} S(s, t)}    {\frac{\partial S(s, t)}{\partial t} \frac{\partial S(s, t)}{\partial s}}
	\end{aligned}
	$$
Which is the coefficient of association derived by Clayton[???] for a specific model. In the context of  Clayton's model, this coefficient was a constant. Dabrowska's  $1-L(du, dv)$ is not a constant and is not a ratio of cahnges in survival functon, but the similarity is facionating. 

\subsubsection{Pruitt, 1991 \cite{pruitt1991negative}}
Pruitt showed that Dabrowska's estimator assigns negative mass to points of $\hat{F}(s,t)$. Although the value of negative mass decreases, the number of such points does not disappear with growing sample size, resulting in non-disappearing negative mass. This problem is related to the problem of identifiability of the bivariate survival functions in the presence of censored data. The proof of Prof. Pruitt is rather complicated, but we can intuitively see why this can be the case. Let's rewrite again Dabrowska's estimator:

	$$
	\begin{aligned}
		\hat{F}(s,t) &= \hat{F}(s,0)\hat{F}(0,t)\cdot \prod_{{0<u\leq s~0<v\leq t}}\{1 - \hat{L}(\Delta u, \Delta v)\}\\
    1 - \hat{L}(\Delta u, \Delta v) &= 1 - \frac{\hat{\Lambda}_{10}(\Delta u,v^-)\hat{\Lambda}_{01}(u^-,\Delta v) - \hat{\Lambda}_{11}(\Delta u,\Delta v)}{\left(1-\hat{\Lambda}_{10}(\Delta u,v^-)\right)\left(1-\hat{\Lambda}_{01}(u^-,\Delta v)\right)}\\
  &where\\
	&\hat{\Lambda}(\Delta t_1, \Delta t_2) = \#(T_1=t_1, T_2=t_2, \delta_1=\delta_2=1)/\#(T_1\geq t_1, T_2\geq t_2)\\
	&\hat{\Lambda}_{10}(\Delta t_1, t_2^-) = \#(T_1=t_1, \delta_1=1, T_2\geq t_2)/\#(T_1\geq t_1, T_2\geq t_2)\\
	&\hat{\Lambda}_{01}(t_1^-,\Delta  t_2) = \#(T_2=t_2, \delta_2=1, T_1\geq t_1)/\#(T_1\geq t_1, T_2\geq t_2)		
	\end{aligned}
	$$
We notice that if expression $1 - \hat{L}(\Delta u, \Delta v)$ is greater than one, then it is possible that $\hat{F}(s,t\neq 0) > \hat{F}(s,0)$. This happens because $\hat{\Lambda}(\Delta t_1, \Delta t_2)$, $\hat{\Lambda}_{10}(\Delta t_1, t_2^-)$, and $\hat{\Lambda}_{01}(t_1^-,\Delta  t_2)$ are estimated from different data: the number of double failures doesn't necessarily correspond to the number of single failures because of censoring.

\subsubsection{Prentice, 1992 \cite{prentice1992covariance}}
This section is summarizing chapter 10 of book of Kalbfleisch and Prentice \emph{The Statistical Analysis of Failure Time Data} \cite{kalbfleisch2011statistical} Regression Models for correlated Failure Time Data. Page 302.

If $\tilde{T}_i$ is the failure time for subject $i$ and $\pmb{x}_i$ is a covariance vector, \textbf{the joint survivor function} is:
	$$
	\begin{aligned}
		F(t_1,...,t_m;x) = P(\tilde{T}_1>t_1,...,\tilde{T}_m > t_m;x)
	\end{aligned}
	$$

Marginal \textbf{first-order }hazard function is:
	$$
	\begin{aligned}
		 \lambda_j(dt_j;x) = P(y_j\leq \tilde{T}_j<t_j + dt_j|\tilde{T}_j \geq t_j,x) ~~~j=1,2,...,m
	\end{aligned}
	$$

Marginal \textbf{first-order }hazard function is:
	$$
	\begin{aligned}
		 \lambda_j(dt_j,dt_k;x) = P(y_j\leq \tilde{T}_j<t_j + dt_j,~y_k\leq \tilde{T}_k<t_k + dt_k~|~\tilde{T}_j \geq t_j,~\tilde{T}_k \geq t_k,~x) ~~~j=1,2,...,m
	\end{aligned}
	$$

The following are notations for representation and estimation of the bivariate survivor function:
	$$
	\begin{aligned}
		F(t_1,t_2) &= P(\tilde{T}_1>t_1,\tilde{T}_2 > t_2)\\
		\Lambda(t_1,t_2) &= \int_0^{t_1} \int_0^{t2} \lambda(du_1, du_2)
	\end{aligned}
	$$
$\Lambda$ \textbf{does not} determine the survivor function over a follow-up region $[0,t_1] \times [0,t_2]$. However, together with the marginal cumulative hazard functions $\Lambda_1$ and $\Lambda_2$ it leads to a \emph{convenient} survivor function estimate with \emph{attractive properties}.\\
First, let's introduce some notations:
\[
F(dt_1, dt_2)=
\begin{bmatrix}
    F^{(11)}(t_1, t_2)dt_1 dt_2 & \text{If F is absolutely continuous in both} \\
        & \text{components at }(dt_1, dt_2) \\
    F^{(10)}(t_1, \Delta t_2)dt_1 & \text{If F is continuous in its first, but not its }\\
        & \text{second argument at }(dt_1, dt_2) \\
    F^{(01)}(\Delta t_1, t_2)dt_2 & \text{If F is continuous in its second, but not its} \\
        & \text{first argument at }(dt_1, dt_2) \\
    F(\Delta t_1, \Delta t_2) & \text{If} (t_1, t_2)\text{ is a mass point}\\
\end{bmatrix}
\]
	$$
	\begin{aligned}
		F(\Delta t_1, \Delta t_2) &= F(t_1^-, t_2^-) - F(t_1^-, t_2) - F(t_1, t_2^-) + F(t_1, t_2)\\
		F(t_1, t_2) &= \int_{t_1}^{\infty} \int_{t_2}^{\infty} F(du_1, du_2)
	\end{aligned}
	$$
\textbf{Bivariate hazard function:}
	$$
	\begin{aligned}
		\Lambda(dt_1, dt_2) &= F(dt_1, dt_2)/F(t_1^-, t_2^-) ~~or\\
		\Lambda(\Delta t_1, \Delta t_2) &= F(\Delta t_1, \Delta t_2)/F(t_1^-, t_2^-)
	\end{aligned}
	$$
It is important to notice that $F(t_1,t_2)$ is not expressed only through $\Lambda$ (see page 309 of Kalbfleisch and Prentice) for the complicated formula. But there is also an easier expression, if we substitute $F(\Delta t_1, \Delta t_2) = \Lambda(\Delta t_1, \Delta t_2) \cdot F(t_1^-, t_2^-)$ into the expression for $F(\Delta t_1, \Delta t_2)$, we get:
	$$
	\begin{aligned}
		F(t_1, t_2) &= F(t_1^-, t_2) + F(t_1, t_2^-) - F(t_1^-, t_2^-)[1-\Lambda(\Delta_1, \Delta_2)]\\
	\end{aligned}
	$$
The above expression is a recursive procedure for estimating $F(t_1, t_2)$ at all failure time points starting with Kaplan-Meier estimates of $F(t_1, 0) = F_1(t_1)$ and $F(t_2, 0) = F_2(t_2)$ given the estimate of $\Lambda(\Delta_1, \Delta_2)$.\\
Dabrowska (1988) inserts a simple estimator $\hat{\Lambda}(\Delta_1, \Delta_2)$, which is a ratio of the number of double failures at $(t_1,t_2)$ to the number of pairs at risk at that point:
	$$
	\begin{aligned}
		\hat{\Lambda}(\Delta t_1, \Delta t_2) = \#(T_1=t_1, T_2=t_2, \delta_1=\delta_2=1)/\#(T_1\geq t_1, T_2\geq t_2)
	\end{aligned}
	$$
This estimator has a reasonably good performance in moderate sample sizes, but is inefficient because of poor correspondence between $\hat{\Lambda}$ and Kaplan-Meier estimates $\hat{F}_1$ and $\hat{F}_2$. Dabrowska (1988) and Prentice\&Cai (1992) tried to improve it by estimating double failure hazard rates in a manner that aknowledge the empirical rate (see the above $\hat{\Lambda}$) and the amount of mass assigned by the Kaplan-Meier marginals along $\tilde{T}_1=t_1$ and along $\tilde{T}_2=t_2$ that remains to be assigned at $(t_1,t_2)$. These estimators were developed using certain product integral and Peano serries representation for the ratio $F(t_1,t_2)/(F_1(t_1)F_2(t_2))$.\\
\emph{Prentice-Cai's} and \emph{Dabrowska's} estimator are given by:
	$$
	\begin{aligned}
		&\hat{\pmb{\Lambda}}_{\pmb{P\&C}}(\Delta t_1, \Delta t_2) 
		=\hat{\Lambda}(\Delta t_1, \Delta t_2) + \hat{L}_1(\Delta t_1, 0)\left[ \hat{L}_2(t_1^-, \Delta t_2)  - \hat{\Lambda}_2(t_1^-, \Delta t_2)\right] + \hat{L}_2(0, \Delta t_2)\left[ \hat{L}_1(\Delta t_1, t_2^-)  - \hat{\Lambda}_1(\Delta t_1, t_2^-)\right]\\
		&\hat{\pmb{\Lambda}}_{\pmb{D}}(\Delta t_1, \Delta t_2) 
		= \hat{L}_1(\Delta t_1, t_2^-)\hat{\Lambda}_2(t_1^-, \Delta t_2)  +  \frac{(1 - \hat{L}_1(\Delta t_1, t_2^-))(1 - \hat{\Lambda}_2(t_1^-, \Delta t_2))}{ (1-\hat{\Lambda}_1(\Delta t_1, t_2^-))  (1-\hat{\Lambda}_2(t_1^-, \Delta t_2))  } \hat{\Lambda}(\Delta t_1, \Delta t_2) - \hat{\Lambda}_1(\Delta t_1, t_2^-)\hat{\Lambda}_2(t_1^-, \Delta t_2)
	\end{aligned}
	$$
Where
	$$
	\begin{aligned}
		&\hat{\Lambda}(\Delta t_1, \Delta t_2) = \#(T_1=t_1, T_2=t_2, \delta_1=\delta_2=1)/\#(T_1\geq t_1, T_2\geq t_2)\\
		&\hat{\Lambda}_1(\Delta t_1, t_2^-) = \#(T_1=t_1, \delta_1=1, T_2\geq t_2)/\#(T_1\geq t_1, T_2\geq t_2)\\
	  &\hat{\Lambda}_2(t_1^-,\Delta  t_2) = \#(T_2=t_2, \delta_2=1, T_1\geq t_1)/\#(T_1\geq t_1, T_2\geq t_2)\\
		&\hat{L}_1(\Delta t_1, t_2^-) = \hat{F}_1(\Delta t_1, t_2^-)/\hat{L}_1(t_1^-, t_2^-)\\
	\end{aligned}
	$$

\subsubsection{van der Laan, 1997 \cite{van1997nonparametric}}
The estimators of Dabrowska and Prentice and Cai:
	$$
	\begin{aligned}
    S(t_1, t_2) &= S_1(t_1)S_2(t_2)R(t_1, t_2);\\
		R(t_1, t_2) &= \frac{S(t_1, t_2)S(0, 0)}{S(t_1)S(t_2)}
 	\end{aligned}
	$$
where $R(t_1, t_2)$ is called \emph{a cross-ratio}(I think) and is a dependence measure between events $T_1>t_1$ and $T_2>t_2$, and $S_j(t_j)$ is a marginal survivor function that is estimated using Kaplan-Meier estimator. The cross-ratio has ''multiplicative property: the cross-ratio over the union of two adjacent rectangles equals the product of the cross-ratios of the rectangles.'' It can be computed iteratively, which leads to the Dbrowska estimator.\\
\\
If we represent $R(t_1, t_2) = e^{log(R(t_1, t_2))}$, then $log(R)$ is  an additive measure over the rectangle $(0,s_1]\times(0,s_2]$ and we can compute:
	
	$$
	\begin{aligned}
		log(R)(t_1, t_2) &= \int_{(0,t_1]\times(0,t_2]} d~log(R)(s_1,s_2)
 	\end{aligned}
	$$

There is a problem (with consistency) with finding these estimators for continuous using EM algorithm because we need to redistribute the mass and there is a problem with it for singly censored observations. This problem was corrected by Pruitt(1991) by using kernel-density estimators. Van der Laan proposed NPMLE based on interval censored singly-censored observations.\\
\\
Under complete independence of events and censoring events, Dabrowska's and Prentice and Cai's estimators did better. With increased dependence, Laan's estimator did better.





\subsection{Developing linear rank tests}

\subsubsection{Prentice, 1978}
Prentice cosidered a linear regression with censored outcome.
	$$
	\begin{aligned}
		y = \alpha + \beta z + \sigma e
	\end{aligned}
	$$
Although this formulation sets up a context for univariate survival, we are interested in this paper for several reasons. The author's goal was to develop a \emph{liear rank statistic} in order to check the hypothesis of $\beta = 0$. In order to do this he had to find an approach to rank survival outcome in the presence of censored data. He chose a simplified approach to the ranking of censored values [Kalbfleisch \& Prentice, 1973]. According to this approach, uncensored observations are ranked between themselves. Censored observations that are located between two adjacent uncencored observations are arbitrarily ranked. This approach allowed to develop linear rank statistic and its approximation that assigned the same score to all censored residuals between adjacent uncensored values.

Even after using ranks and approximations, Prentice's approach required assuming $F_i$ - distribution of residuals (check this please).

\subsubsection{Cuzick, 1982}
Considers a general model of association:
	$$
	\begin{aligned}
		Y_1 = aZ + e_1 ~~~~~~~~ Y_2 = bZ + e_2
	\end{aligned}
	$$

Where $Z$, $e_1$, and $e_2$ are independent and  $b=a\lambda,~~0<|\lambda|<\infty$. In this case two variables $(Y_1, Y_2)$ are thought to be related to a third unobserved covariate.\\
He assumed the same generalized ranking of censored data as Prentice (1978): the uncensored observations are ranked and the censored observations can be arbitralily ranked, which also includes giving the same rank as the closest uncensored observation to the left of the censored point. Also, similar to Prentice (1978), Cuzick's approach required knowing $f_i(x)$ the density of $e_i$. He illustrated his approach by showing that when this density is logistic, $f(x) = 2\pi_{-1} e^{-x}/(1+e^{-x})^2$, then the rank of each observation is $F(x)$ with no censoring, and $\frac{1+F(x)}{2}$, when censoring is present - \textbf{PSR}
% \subsection{P. Gaduthol Sankaran, B. Abraham, A Alphonsa Antony, 2006: A dependence measure for bivariate failure time data, ref???}
% Meaning to improve over the measures given by Fan et al. (1998) and Fan et al. (2000), the authors propose a \emph{covariance residual life function} (CVRL) as a dependence measure of bivariate falure time data:
% 	$$
% 	\begin{aligned}
% 		 C(t_1, t_2) &= M(t_1, t_2) - r_1(t_1, t_2) r_2(t_1, t_2) =\\
% 		  &=E[(T_1-t_1)(T_2-t_2)|T_1>t_1,T_2>t_2] - E[T_1-t_1|T_1>t_1,T_2>t_2]\cdot E[T_2-t_2|T_1>t_1,T_2>t_2]
% 	\end{aligned}
% 	$$
% They note that this measure is in fact a weighted average of the Clayton's $\theta(t_1,t_2) = \frac{S(t_1,t_2)D_1D_2(S(t_1,t_2))}{D(S(t_1,t_2))D_2(S(t_1,t_2))}$ with a weight $\left[ \frac{D_1D_2(S(t_1,t_2))}{D_1(S(t_1,t_2))D_2(S(t_1,t_2))} \right]^{-1}$.

\subsubsection{Dabrowska, 1986 \cite{dabrowska1986rank}}
The author discusses statistics to check independence of two failure times, possibly censored: $H_0:~F=F_1 F_2$. Unlike Cuzick [ref???], she does not assume any model, but the assumption of failure times are still necessary. the author has continued the development of non-parametric test for bivariate survival. further the approach of [Prentice, 1978], [Kalbfleisch \& Prentice, 1980], and [Cuzick, 1982], . The author suggested that  the following \emph{linear rank} statistic can be used
	$$
	\begin{aligned}
		 &\sum_{n=1}^N a_1(R_{1n}, \delta_{1n})\cdot a_2(R_{2n}, \delta_{2n}), ~i=1,2\\
		 &~~~~~ a_i(j,d) = E\mathcal{J}(U_{(j)}, d)\prod_{k=1}^{N_i} m_{ik}(1-U_{(k)})^{a_{ik}}
	\end{aligned}
	$$
Where: 
	$$
	\begin{aligned}
		 R_in &= \#\{m:~Y_{im} \leq Y_{in}, \delta_{im}=1   \}\\
		 a_{ik} &= \# \{n: ~R_{in}=k,~\delta_{in}=0\}\\
		 m_{ik} &= \# \{n: ~R_{in}\geq k\}\\
		 \delta_{im}&=1,~if~subject ~m~from~group~i~has~an~event\\
		 U_{(k)}~&independent ~ordered~sample~from~Uniform~distribution\\
		 \mathcal{J}(u,d) ~&is~such~that:~~\int_0^u \mathcal{J}_i(v,1)dv = -(1-u)\mathcal{J}_i(u,0)
	\end{aligned}
	$$
She also notes that the exact scores are hard to compute, so similarly to Prentice [1978???], Kalbfleisch and Prentice [1980???], and Cuzick [1982], the author uses an approximate test statistic:
	$$
	\begin{aligned}
		 S_n = \sum_{n=1}^N \mathcal{J}_1( \hat{F}_1, \delta_{1n}) \cdot \mathcal{J}_2( \hat{F}_2, \delta_{2n})
	\end{aligned}
	$$
Where $\hat{F}_i$ are estimators close to the usual \emph{Kaplan-Meier} estimators of the marginal \emph{CDF}'s.

She shows that different failure distribution functions result in different tests. Specifically, the choice of $\mathcal{J}_i(u,d) =d-(1+d)u$ corresponds to the cencored-data version of the Spearman test. Substituting this choice of $\mathcal{J}_i(u,d)$ into the above expression, we get:
	$$
	\begin{aligned}
		 S_n &= \sum_{n=1}^N (\hat{F}_1 - \delta_{1n}(1-\hat{F}_1))\cdot (\hat{F}_2 - \delta_{2n}(1-\hat{F}_2))\\
	\end{aligned}
	$$
The above expression reminds us of $E[PSR_1 \cdot PSR_2]$, where $PSR(x, \delta) = F(x)-\delta(1-F(x))$ is a probability scale residual, \textbf{PSR}, for continuous and censored failure time. 

\subsubsection{Shih, Louis, 1996, \emph{Test of Independence for Bivariate Survival Data}, ref???}
\textbf{Motivation}: Leukemia patients that undergo bone marrow transplantation are at risk of \emph{acute graft versus host disease (AGVHD)} and \emph{cytomegalovirus (CMV)}, and the question is if these events are correlated:

The authors consider martingale residuals, $M_{ij}$, which is the difference between observed and expected deaths. They base their new statistic on the result of Clayton and Cuzick (1985 ???) who developed a model for bivariate time to event with frailties, and suggested the following test statistic that measured the sample covariance of the martingale residuals:
$$
\begin{aligned}
  T_n=\sum_i \left\{ \delta_{i1} - \hat{\Lambda}(X_{i1}) \right\} \left\{ \delta_{i2} - \hat{\Lambda}(X_{i2}) \right\} =\sum_i \int_0^{t_0}  \int_0^{t_0} d\hat{M}_{i1}(u_1) d\hat{M}_{i2}(u_2).
\end{aligned}
$$ 
 
Shih and Louis suggested to improve its power by introducing the following two statistics:

\begin{enumerate}
	\item take supremum: $U_n= \sup_{0\leq t \leq t_0} \left|\sum_i \int_0^{t_0}  \int_0^{t_0} d\hat{M}_{i1}(u_1) d\hat{M}_{i2}(u_2)\right|$
	\item weigh it: $V_n= \sum_i \int_0^{t_0}  \int_0^{t_0} W_n(u_1,u_2) d\hat{M}_{i1}(u_1) d\hat{M}_{i2}(u_2)$ (which is analogous to the weighted logrank test)
\end{enumerate}
They choose \emph{optimal} weights by somehow using the \emph{cross ratio} defined by Oakes $\theta = \frac{ \frac{\partial^2 S(s,t)}{\partial s \partial t} S(s, t)}    {\frac{\partial S(s, t)}{\partial t} \frac{\partial S(s, t)}{\partial s}}$: 

Although statistic $U_n$ is a supremum over $t_1=t_2$, the simulations showed promising results.
For $V_n$, if the weights are not specified correctly, the test based on $V_n$ looses power.

\subsubsection{Ding, Wang, 2012: Testing Independence for Bivariate Current Status Data, ref???}
Suggested two statistics for testing independence for bivariate \emph{current status data}. One is based on counts (how many events, non-events, and so forth). The other one is:
	$$
	\begin{aligned}
		 E[cov(\delta_1, \delta_2)|C_1,C_2] = E\left\{ [\delta_1 - F_1(C_1)][\delta_2 - F_2(C_2)]  \right\}\\
	\end{aligned}
	$$
Which is \textbf{exactly} covariance of \textbf{PSR} for \emph{current status data}.





\subsection{PSR (probability scale residuals) for censored data}
% Terms for residuals:
% \begin{itemize}
% 	\item \textbf{OMER}-observed minus expected residuals: $E(y-Y^*) = y - \hat{y}$
% 	\item \textbf{PSR}-probability scale residuals: $E{sign(y,Y^*)} = pr(Y^* < y) - pr(Y^* > y)$
% \end{itemize}
PSR are defined as $r(t,F^*) = E\{sign(y,Y^*)\} = pr(Y^* < y) - pr(Y^* > y) = F^*(t-) - (1-F^*(y)) = F^*(t-) - 1 + F^*(t)$.\\
Since we do not always observe $t$, the PSR must be defined in terms of $y$ (time to event or censoring) and $\delta$ (if the event happened or not). \\
\\
\textbf{By definition}, $r(y,F^*, \delta) = r(t,F^*|\Delta=\delta)$.\\
If $\delta = 1$, then $t=y$ and $r(y,F^*, \delta=1) = F^*(y-) - 1 + F^*(y)$. \\
If $\delta = 0$, then $t$ is unknown, except that it occurs some time after the censoring time $y$, so $r(t,F^*, \delta=0) = E\{r(t,F^*)|T^*>y\}$. Let's find it:
	$$
	\begin{aligned}
		E\{r(t,F^*)|T^*>y\} &= \frac{\int_{t>y}r(t,F^*)dF^*(t)}{1-F^*(t)}= \frac{\int_{t>y}(F^*(t-) - 1 + F^*(t))dF^*(t)}{1-F^*(y)}= \frac{\int_{t>y}F^*(t-)dF^*(t) - \int_{t>y}(1 - F^*(t))dF^*(t)}{1-F^*(y)}=\\
		&= \frac{\int_{t>y}\int_{s<t}dF^*(s)dF^*(t) - \int_{t>y}\int_{s>t}dF^*(s)dF^*(t)}{1-F^*(y)}= \frac{\int_{t>y}\int_{s<t}dF^*(s)dF^*(t) - \int\int_{y<t<s}dF^*(s)dF^*(t)}{1-F^*(y)}=\\
		&= \frac{\left[\int\int_{s<y<t}dF^*(s)dF^*(t) + \int\int_{y<s<t}dF^*(s)dF^*(t)\right] - \int\int_{y<t<s}dF^*(s)dF^*(t)}{1-F^*(y)}\\
	\end{aligned}
	$$
Because $t$ and $s$ are symmetric, $\int\int_{y<s<t}dF^*(s)dF^*(t) = \int\int_{y<t<s}dF^*(s)dF^*(t)$, so we have:
	$$
	\begin{aligned}
		E\{r(t,F^*)|T^*>y\} &= \frac{\left[\int\int_{s<y<t}dF^*(s)dF^*(t) + \cancel{\int\int_{y<s<t}dF^*(s)dF^*(t)}\right] - \cancel{\int\int_{y<t<s}dF^*(s)dF^*(t)}}{1-F^*(y)}\\
		&= \frac{\int\int_{s<y<t}dF^*(s)dF^*(t)}{1-F^*(y)} = \frac{(1-F^*(y))\int_{s<y}dF^*(s)}{1-F^*(t)} = \frac{\cancel{(1-F^*(y))}F^*(y)}{\cancel{1-F^*(y)}} =\\
		&=F^*(y)
	\end{aligned}
	$$
	
Therefore for censored data:
	$$
	\begin{aligned}
		r(y, F^*) &= F^*(y) + F^*(y-) - 1,~~~&\delta = 1 \\
		r(y, F^*) &= F^*(y) ,~~~&\delta = 0 \\
	\end{aligned}
	$$
or $r(y, F^*) = F^*(y) + \delta((F^*(y-) - 1)$.

\subsubsection{Spearman correlation and PSR correlation for continuous censored outcome}
Here we show that if we define Spearman correlation for continuous and censored outcomes a certain way, we then Spearman correlation and PSR correlation for ontinuous censored outcome are equivalent.\\
~\\
Spearman correlation for continuous outcome can be defined as $cor(F_S(s), F_T(t))$ (reference ???). In case of censored outcomes however, we don't always know $s$ and $t$. This means that we have to redefine Spearman correlation in a different way. In the following section we use $S$, $C$, $\delta=I(S\leq C)$, $X = min(S, C)$ for the first outcome and $T$, $D$, $\epsilon=I(T\leq D)$, $Y = min(T, D)$ for the second.\\
Let's modify the definition of the Spearman correlation in the following way. When $\delta = 1$ or $S\leq C$, we have that $X = min(S, C)=S$ and instead of $F_S(s)$ we can take $F_S(x)$. When $\delta = 0$ or $S > C$, we have that $X = min(S, C)=C$ and instead of $F_S(s)$ we can take $E_S[F_S(s)|S>x]$. Let's compute $E_S[F_S(s)|S>x]$:
	$$
	\begin{aligned}
		E_S[F_S(x)|S>x] &= \frac{1}{1-F_S(x)}\int_{(x, \infty)} F_S(s)dF_S(s) = \frac{1}{1-F_S(x)} \left.\frac{ [F_S(s)]^2}{2}\right|_{(x, \infty)} = \frac{1-[F_S(x-)]^2}{2(1-F_S(x))} \\
	\end{aligned}
	$$
Since we are focusing now on the continuous case, we can assume that $F_S(x)=F_S(x-)$ therefore we have
	$$
	\begin{aligned}
		E_S[F_S(x)|S>X] &=\frac{1-[F_S(x)]^2}{2(1-F_S(x))}=\frac{\cancel{(1-F_S(x))}(1+F_S(x))}{2\cancel{(1-F_S(x))}}  = \frac{1+F_S(x)}{2} \\
	\end{aligned}
	$$
So, instead of looking at the Spearman correlation as correlation of $F_S(s)$ and $F_T(t)$, we redefine correlation as:
	$$
	\begin{aligned}
		Spearman~correlation~&=~ cor\left(  \delta F_S(x) + (1-\delta) \frac{1+F_S(x)}{2},~\epsilon F_T(y) + (1-\epsilon) \frac{1+F_T(y)}{2}  \right)\\
		&=~ cor\left(  \frac{1+\delta}{2}F_S(x) +  \frac{1-\delta}{2},~\frac{1+\epsilon}{2}F_T(y) +  \frac{1-\epsilon}{2}  \right)\\
		&=~ cor\left(  (1+\delta)F_S(x) +  1-\delta,~(1+\epsilon)F_T(y) +  1-\epsilon  \right)\\
	\end{aligned}
	$$
It is easy to check that in the continous case, the above expression is the same as: 
	$$
	\begin{aligned}
		PSR~correlation~&=~ cor\left(  (1+\delta)F_S(x) -\delta,~(1+\epsilon)F_T(y) -\epsilon  \right)\\
	\end{aligned}
	$$

\subsubsection{Spearman correlation and PSR correlation for discrete censored outcome}
For discrete case, Spearman correlation can be defined as (???):
	$$
	\begin{aligned}
		cor\left( \frac{F_S(s) + F_S(s-)}{2},~\frac{F_T(t) + F_T(t-)}{2} \right)\\
	\end{aligned}
	$$
So let's find $E_S[F_S(x)|S>x]$ for the discrete case. First (just to get started) let's derive $E_S[F_S(x)]$. We denote $Pr\left\{S=s\right\}$ as $P_s$:
	$$
	\begin{aligned}
		E_S[F_S(x)] &= \sum_{i=0}^{\infty}F_S(i)P_i = \sum_{i=0}^{\infty}\left( \sum_{k=0}^{i}P_k \right)P_i =\\
		&= (P_0 P_0) + (P_0 P_1 + P_1 P_1) + (P_0 P_2 + P_1 P_2 + P_2 P_2) + ...= \\
		&= P_0^2 + P_1^2 + P_2^2 + ... + P_0 P_1 + P_0 P_2 + P_2 P_1 + ... =\frac{1}{2}(P_0 + P_1 + P_2 + ...)^2 + \frac{1}{2}(P_0^2 + P_1^2 + P_2^2 + ...) =\\
		&= \frac{1}{2} + \frac{1}{2}\sum_{i=0}^{\infty}P_i^2
	\end{aligned}
	$$
Now we are equiped to compute $E_S[F_S(x)|S>x]$:
	$$
	\begin{aligned}
		E_S[F_S(x)|S>x] &= \frac{1}{1-F_S(x)} \sum_{i=x+1}^{\infty}F_S(i)P_i = \frac{1}{1-F_S(x)}\sum_{i=x+1}^{\infty}\left( \sum_{k=0}^{i}P_k \right)P_i =\\
		 &= \frac{1}{1-F_S(x)}\left[ \sum_{i=0}^{\infty}\left( \sum_{k=0}^{i}P_k \right)P_i - \sum_{i=0}^{x}\left( \sum_{k=0}^{i}P_k \right)P_i   \right] = \\
		 &= \frac{1}{1-F_S(x)}\left[ \frac{1}{2} + \frac{1}{2}\sum_{i=0}^{\infty}P_i^2 -  \frac{1}{2} \left\{ \left(\sum_{i=0}^{x}P_i\right)^2 + \sum_{i=0}^{x}P_i^2  \right\}    \right] = \\
		 &= \frac{ 1 - F_S^2(x) + \sum_{i=x+1}^{\infty}P_i^2 }{2(1-F_S(x))}\\
	\end{aligned}
	$$

Our next challenge is to compute $E_S[F_S(x-)|S>x]$. We assume that $F_S(0-)=0$:
	$$
	\begin{aligned}
		E_S[F_S(x-)|S>x] &= \frac{1}{1-F_S(x)} \sum_{i=x+1}^{\infty}F_S(i-1)P_i = \frac{1}{1-F_S(x)}\sum_{i=x+1}^{\infty}\left( \sum_{k=0}^{i-1}P_k \right)P_i =\\
		 &= \frac{1}{1-F_S(x)}\left[ \sum_{i=0}^{\infty}\left( \sum_{k=0}^{i-1}P_k \right)P_i - \sum_{i=0}^{x}\left( \sum_{k=0}^{i-1}P_k \right)P_i   \right] = \\
		 &= \frac{1}{1-F_S(x)}\left[ \frac{1}{2} - \frac{1}{2}\sum_{i=0}^{\infty}P_i^2 -  \frac{1}{2} \left\{ \left(\sum_{i=0}^{x}P_i\right)^2 - \sum_{i=0}^{x}P_i^2  \right\}    \right] = \\
		 &= \frac{ 1 - F_S^2(x) - \sum_{i=x+1}^{\infty}P_i^2 }{2(1-F_S(x))}\\
	\end{aligned}
	$$
Now, let's recall that in the discrete case each Spearman correlation component is $\frac{F_S(s) + F_S(s-)}{2}$, so let's compute it for the case when $\delta=0$:
	$$
	\begin{aligned}
	  \frac{E_S[F_S(x)|S>x] + E_S[F_S(x-)|S>x]}{2} &= \frac{1}{2}\left[\frac{ 1 - F_S^2(x) + \sum_{i=x+1}^{\infty}P_i^2 }{2(1-F_S(x))}   +   \frac{ 1 - F_S^2(x) - \sum_{i=x+1}^{\infty}P_i^2 }{2(1-F_S(x))}\right]=\\
		&= \frac{1 - F_S^2(x)}{2(1-F_S(x))}= \frac{1 + F_S(x)}{2}\\
	\end{aligned}
	$$
As a result, we have:
	$$
	\begin{aligned}
		Spearman~correlation~&=~ cor\left(  \delta\frac{F_S(x) + F_S(x-)}{2} + (1-\delta) \frac{1 + F_S(x)}{2}, ~\epsilon\frac{F_T(y) + F_T(y-)}{2} + (1-\epsilon) \frac{1 + F_T(y)}{2} \right)=\\
		&=~ cor\left(  \delta( F_S(x) + F_S(x-)) + (1-\delta) (1 + F_S(x)), ~\epsilon (F_T(y) + F_T(y-)) + (1-\epsilon) (1 + F_T(y)) \right)=\\
		&=~ cor\left( \cancel{\delta F_S(x)} + \delta F_S(x-) +  1 + F_S(x) -\delta - \cancel{\delta F_S(x)}, ~\cancel{\epsilon F_T(y)} + \epsilon F_T(y-) + 1 + F_T(y)-\epsilon -\cancel{\epsilon F_T(y)}   \right)=\\
		&=~ cor\left( F_S(x) + \delta F_S(x-) +  1 -\delta , ~ F_T(y) + \epsilon F_T(y-) + 1 -\epsilon   \right)\\
	\end{aligned}
	$$
It can be easily shown that the above expression is the same as correlation of \emph{PSR}:
	$$
	\begin{aligned}
		PSR~correlation~&=~ cor\left(  F_S(x) + \delta F_S(x-) -\delta,~F_T(y) + \epsilon F_T(y-) -\epsilon  \right)\\
	\end{aligned}
	$$

\subsubsection{Spearman correlation and PSR based on a different definition.}
Up to now, in order to prove the equivalence of \emph{Spearman} corrlation and the correltation of the PSR we have been using the following defition of \emph{Spearman} correlation: $corr(F_S(s), F_T(t))$. In this section, we show that if we start with the original definition, $E(sign(S_1-S_0)sign(T_2-T_0))$, we will get the same result. Let's see why. Keeping in mind that $S_1 \perp T_2$ we can write:
	$$
	\begin{aligned}
		E(sign(S_1-S_0)sign(T_2-T_0)) &= E_{(S,T)}\left\{ E[sign(S_1-S_0)sign(T_2-T_0) |(S_1,T_2)] \right\} = \\
		  &= E_{(S,T)}\left\{ E[sign(S_1-S_0) |S_1]  E[sign(T_2-T_0) |T_2] \right\} = \\
		  &= E_{(S,T)}\left\{ [ P(S_0 < S_1|S_1) - P(S_0 > S_1|S_1) ] \cdot  [P(T_0 < T_2|T_2) - P(T_0 > T_2|T_2)] \right\}
	\end{aligned}
	$$
 Now, let's look at the expression $P(S_0 < S_1|S_1) - P(S_0 > S_1|S_1)$. We already know that in case of no censoring, $P(S_0 < S_1|S_1) - P(S_0 > S_1|S_1) = PSR(S_1)$. When censoring takes place, we don't observe $S_1$, but we still obsere $x_1$, so similarly to the previous section, instead of $P(S_0 < S_1|S_1) - P(S_0 > S_1|S_1)$ we can take:
	$$
	\begin{aligned}
		 E_{S_0>x_1}[P(S_0 < x_1)|S_0>x_1] - E_{S_0>x_1}[P(S_0 > x_1)|S_0>x_1]&= 0 - \frac{1}{1-F_S(S>x_1)}\int_{(x_1, \infty)} F_S(s)dF_S(s)
	\end{aligned}
	$$
We have already proved in the previous sections, that taking a correlation of the product of the right hand side expressions above results in Spearman correlation (the minus signs cancel out).

\subsection{Probability scale residual as a measure of association for censored outcomes, continuous or discrete}
Correlation of PSR is in fact a Spearman correlation generalized to the case with censoring. Although, Cuzick1982, Dabrowska1986, and Ding2012 described statistics indentical to PRS in continuous case, their derivations were done in a semi-parametric setting with very specific assumptions about the distribution of time to event. Spearman correlation of PSR requires very little assumptions (what assumptions???) and is a non-parametric way of measuring association. In addition, PSR are generalized to discrete case for the case of independent censoring and for the case of currents status data.\\

Future direction: We want to develope conditional and partial PSR, we want to evaluate the performance of PSR under different distributions, functional dependence, and percent of censoring.
	

\subsection{Zhang, 2008: Inference on the association measure for bivariate survival data with hybrind censoring and applications to an HIV study, ref???}
The author uses archimedian copulas and Kendall's $\tau$ to assess association of bivariate survival data with hybrid censoring.

\section{Summary of: An Adjustment to Improve the Bivariate Survivor Function Repaired NPMLE. Moodie, Prentice, 2005 \cite{moodie2005adjustment}}


\subsection{Alvo and Cabilio, 1995 citation ?????}
UNDER CONSTRUCTION.\\
The authors use a concept of distance applied to \emph{Spearman} and \emph{Kendal} correlation measure in order to build a test that can deal with missing data. 

\section{Dabrowska example}
\begin{verbatim}
library(survival)
kmdata = data.frame(Y1 = c(.51, .68, .11, .24), d1 = c(1, 1, 1, 0), Y2 = c(.02, .68, .62, .24), d2 = c(1, 1, 0, 0))
KM1 <- survfit( Surv(kmdata$Y1, kmdata$d1)~ 1)$surv
KM2 <- survfit( Surv(kmdata$Y2, kmdata$d2)~ 1)$surv
KM1
KM2

X = c(rep(.11, 4), rep(.24, 4), rep(.51, 4), rep(.68, 4))
Y = c(rep(c(.02, .24, .62, .68), 4))
lam11 = c(rep(0, 8),   .25, .25, 1/3, 1/2,   .25, .25, 1/3, 1)
lam10 = c(rep(.25, 4),    rep(0, 4),   rep(.5,4),   rep(1,4))
lam01 = c(rep(c(.25, 0, 0, 1), 4))
L = (lam10*lam01 - lam11)/((1 - lam10)*(1 - lam01))
bivarSurvEstData = data.frame(X=X, Y=Y, KM1=rep(KM1, each=4), KM2 = rep(KM2, 4), L=L)

############## estimator at point (X,Y) = (.51, .02):
L_11_02 = bivarSurvEstData$L[bivarSurvEstData$X == .11 & bivarSurvEstData$Y == .02]
L_24_02 = bivarSurvEstData$L[bivarSurvEstData$X == .24 & bivarSurvEstData$Y == .02]
L_51_02 = bivarSurvEstData$L[bivarSurvEstData$X == .51 & bivarSurvEstData$Y == .02]
KM1_51_02 = bivarSurvEstData$KM1[bivarSurvEstData$X == .51 & bivarSurvEstData$Y == .02]
KM2_51_02 = bivarSurvEstData$KM2[bivarSurvEstData$X == .51 & bivarSurvEstData$Y == .02]

BivarSurvEstimate_51_02 = KM1_51_02 * KM2_51_02 * (1-L_11_02) * (1-L_24_02) * (1-L_51_02)
BivarSurvEstimate_51_02

l11 = .25
l10 = 0.5
l01 = 0.25
(l10*l01 - l11)/((1 - l10)*(1 - l01))

l11 = .25
l10 = .25
l01 = 0
(l10*l01 - l11)/((1 - l10)*(1 - l01))
\end{verbatim}


\section{Oral Exam Stuff}
~\\
\begin{itemize}
	\item Martingale residuals (Shih\&Louice, [??? look for more papers on martingale residuals])
	\item sort of hazard ratio for bivariate survival (Clayton, Oakes, Fan, Sankaran et al)
	\item copulas (zhang2008, [??? provide more references on copulas])
	\item distance measure [??? not sure if I want to address this]
	\item Spearman correlation (Dabrowska1986, Ding2012, Cuzick1982)
	\item Probability scale residuals, PSR (Li\&Shepard)
	\item Challanges and limitations (discrete data covariates)
	\item Qi - covariates (look at prentice and Cuzick)
	\item show that this is Spearman
	\item apply to dataset
	\item simmulations
	\item explore performance of partial and conditional Spearman.
	\item read Alvo and Cabilio, 1993:
	\item look into Shih \& Louis, 1996: \emph{who sites those and what this is about (Louis is apparently known)}.
	\item Look who cited Betensky, Filkenstein, AIDS, 1999: paper
Tests of independence for bivariate survival data:
	\item Understand Qi's conditional, partial, and conditional-partial correlation
	\item Find out about Spearman test (unlike Spearman's correlation)
	\item Develop Spearman correlation for different $s$ and $t$: instead of having one number $\rho$ develop a new measure $\rho(s, t)$.
	\item \textbf{READ: Hanley, J. A., and Parnes, M. N. (1983), Nonparametric Estimation of a Multivariate Distribution in the Presence of Censoring, Biometrics, 39, 129-139.}

\end{itemize}
~\\

\printbibliography

\end{document}          

